<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Lightning-dev] Route finding and route generation
   </TITLE>
   <LINK REL="Index" HREF="https://lists.linuxfoundation.org/pipermail/lightning-dev/2017-September/index.html" >
   <LINK REL="made" HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20Route%20finding%20and%20route%20generation&In-Reply-To=%3CCAGpPWDZmZep26zzvy-io8zZchoFrExVxW2p__6aZ3mKN9NAf_g%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000758.html">
   <LINK REL="Next"  HREF="000760.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Lightning-dev] Route finding and route generation</H1>
    <B>Billy Tetrud</B> 
    <A HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20Route%20finding%20and%20route%20generation&In-Reply-To=%3CCAGpPWDZmZep26zzvy-io8zZchoFrExVxW2p__6aZ3mKN9NAf_g%40mail.gmail.com%3E"
       TITLE="[Lightning-dev] Route finding and route generation">billy.tetrud at gmail.com
       </A><BR>
    <I>Mon Sep  4 20:48:54 UTC 2017</I>
    <P><UL>
        <LI>Previous message: <A HREF="000758.html">[Lightning-dev] Route finding and route generation
</A></li>
        <LI>Next message: <A HREF="000760.html">[Lightning-dev] [MINUTES] Dev Meeting 2017-09-04
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#759">[ date ]</a>
              <a href="thread.html#759">[ thread ]</a>
              <a href="subject.html#759">[ subject ]</a>
              <a href="author.html#759">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Thanks for the information Laolu! I'm glad people smarter than me are
working on this : ) . Do you have any idea when Flare might be ready for
real-world use?

~BT

On Mon, Sep 4, 2017 at 1:02 PM, Olaoluwa Osuntokun &lt;<A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">laolu32 at gmail.com</A>&gt;
wrote:

&gt;<i> Hi,
</I>&gt;<i>
</I>&gt;<i> Welcome to the mailing list!
</I>&gt;<i>
</I>&gt;<i> Replying here rather than the issue you filed on the lighting-rfc repo as
</I>&gt;<i> I'd say this is a better venue to discuss matters such as this. The
</I>&gt;<i> structure of the mailing list may be a bit strange initially, but once you
</I>&gt;<i> get over that hump, I think you'll find it's rather pleasant to use. Also,
</I>&gt;<i> if you stick around, you'll find that most members of the Bitcoin
</I>&gt;<i> development community use technical mailing lists such as this one to
</I>&gt;<i> share ideas, propose new solutions, analyze existing schemes, etc.
</I>&gt;<i>
</I>&gt;<i> This list has been a bit lower traffic recently than compared to the past
</I>&gt;<i> as many of us have locked ourselves in dungeons coding without pants as
</I>&gt;<i> we're rapidly approaching the first mainnet release of our various
</I>&gt;<i> lightning node software. As a result, replies may have a bit of delay, but
</I>&gt;<i> that's nothing to fret about!
</I>&gt;<i>
</I>&gt;<i> &gt; I propose a protocol where each node knows about its own local network
</I>&gt;<i> &gt; topology, and to find a final route, a transaction originator queries a
</I>&gt;<i> &gt; number of its connections for routes to the intended destination.
</I>&gt;<i>
</I>&gt;<i> For color, I'm one of the co-authors of the Flare paper. What you've
</I>&gt;<i> described in this email is close to the approach, but it utilizes a blind
</I>&gt;<i> all-the-links flood towards the destination, rather than a DFS search
</I>&gt;<i> guided by the distance metric proposed in the paper. One thing to note is
</I>&gt;<i> that Flare utilizes HORNET to allow senders to query their beacon nodes,
</I>&gt;<i> and also nodes beyond the horizon of their beacon nodes in a private
</I>&gt;<i> manner.  By using the bi-directional communication circuit, we maintain
</I>&gt;<i> requester anonymity, and don't force those performing search to reveal
</I>&gt;<i> their identity nor intent. Also note that Flare itself also uses an
</I>&gt;<i> initial routing cache for a neighborhood of N nodes.
</I>&gt;<i>
</I>&gt;<i> What you've described here is essentially Dynamic Source Routing (DSR)[1],
</I>&gt;<i> with a mix of components from Fisheye State Routing (FSR) making it a
</I>&gt;<i> hybrid protocol that combines reactive and proactive elements in order to
</I>&gt;<i> achieve its goals.
</I>&gt;<i>
</I>&gt;<i> Our current stop-gap is a pure proactive protocol, meaning that nodes
</I>&gt;<i> gather all link state data and then make forwarding and
</I>&gt;<i> routing decisions based off of that. The clear trade off (as you point
</I>&gt;<i> out), is the increase in table state and bandwidth incurred due to keeping
</I>&gt;<i> up with the announcements. The upside is that the latency observed when
</I>&gt;<i> attempting payments to random sections of the graphs are minimized.
</I>&gt;<i> Additionally, as we have complete information, we can make more
</I>&gt;<i> intelligent path finding decisions, and also ensure that we collect a
</I>&gt;<i> redundant set of routes for each payment. By ensuring that we collect a
</I>&gt;<i> set of routes with high path diversity, we have many options to fall back
</I>&gt;<i> to in the case of a routing failure with one of the earlier routes in our
</I>&gt;<i> set.
</I>&gt;<i>
</I>&gt;<i> However, protocols that have a reactive element for each circuit
</I>&gt;<i> establishment may not necessarily scale better. This is due to the
</I>&gt;<i> computational overhead of circuit establishment. Particularly in your
</I>&gt;<i> DSR+FSR combo as the flood proceeds in all directions. As a result,
</I>&gt;<i> circuit establishment may have latency in the seconds as each random
</I>&gt;<i> payment may potentially need to flood out in the graph in search of the
</I>&gt;<i> destination. Without a sort of distance metric to guide the search, it
</I>&gt;<i> may wastefully explore non-relevant sections, further increasing payment
</I>&gt;<i> latency and overhead for all other nodes. Finally, one aspect to consider
</I>&gt;<i> is how DoS-able schemes like this that require flooding for each circuit
</I>&gt;<i> establishment are.
</I>&gt;<i>
</I>&gt;<i> &gt; When a node wants to construct a route for a transaction:
</I>&gt;<i> &gt; 2. It asks all the channels on the edge of its cached local view for
</I>&gt;<i> &gt; their cheapest path
</I>&gt;<i>
</I>&gt;<i> Simply _asking_ nodes for a path to a destination defeats the point of
</I>&gt;<i> using onion routing at all. If one is prepared to make that tradeoff, then
</I>&gt;<i> far more scalable routing protocols can be explored as at that point, one
</I>&gt;<i> would move to distance vector based algorithms.
</I>&gt;<i>
</I>&gt;<i> Very happy to see that more folks are exploring alternative
</I>&gt;<i> routing/discovery solutions! In the future we'll definitely need to scale
</I>&gt;<i> up the network.
</I>&gt;<i>
</I>&gt;<i> One beauty of the way the system is laid out is that multiple
</I>&gt;<i> heterogeneous routing protocols can be used within the network just as
</I>&gt;<i> within the Internet (eBGP vs iBGP), so different sub-graphs can chose
</I>&gt;<i> protocols that achieve their goals in light of the various tradeoffs. I
</I>&gt;<i> think I'll follow up this post with a general survey of potential
</I>&gt;<i> approaches I've come up with and come across in the literature along with
</I>&gt;<i> their various tradeoffs, and possible paths forward for the network as a
</I>&gt;<i> whole.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> -- Laolu
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> [1]: <A HREF="https://arxiv.org/pdf/1507.05724.pdf">https://arxiv.org/pdf/1507.05724.pdf</A>
</I>&gt;<i> [2]: <A HREF="http://www.utdallas.edu/~ksarac/Papers/DSR.pdf">http://www.utdallas.edu/~ksarac/Papers/DSR.pdf</A>
</I>&gt;<i> [3]: <A HREF="http://nrlweb.cs.ucla.edu/publication/download/203/05">http://nrlweb.cs.ucla.edu/publication/download/203/05</A>_
</I>&gt;<i> 75_fisheye-state-routing-in.pdf
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Mon, Aug 21, 2017 at 6:09 PM Billy Tetrud &lt;<A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">billy.tetrud at gmail.com</A>&gt;
</I>&gt;<i> wrote:
</I>&gt;<i>
</I>&gt;&gt;<i> Hey Guys,
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I'm testing this mailing list out for the first time, so I'm probably
</I>&gt;&gt;<i> gonna be doing it wrong.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I want to talk about route discovery and route generation in the
</I>&gt;&gt;<i> lightning network. It seems there's a couple types of things going on with
</I>&gt;&gt;<i> routing:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>    - Super basic flood-the-network style routing to get things up and
</I>&gt;&gt;<i>    running, as I believe is implicitly proposed here: <A HREF="https://github.com/">https://github.com/</A>
</I>&gt;&gt;<i>    lightningnetwork/lightning-rfc/blob/master/07-routing-gossip.md
</I>&gt;&gt;<i>    &lt;<A HREF="https://github.com/lightningnetwork/lightning-rfc/blob/master/07-routing-gossip.md">https://github.com/lightningnetwork/lightning-rfc/blob/master/07-routing-gossip.md</A>&gt;
</I>&gt;&gt;<i>    - More involved research projects that may not reach fruition any
</I>&gt;&gt;<i>    time soon. Eg this: <A HREF="http://bitfury.com/content/5-white-papers-">http://bitfury.com/content/5-white-papers-</A>
</I>&gt;&gt;<i>    research/whitepaper_flare_an_approach_to_routing_in_
</I>&gt;&gt;<i>    lightning_network_7_7_2016.pdf
</I>&gt;&gt;<i>    &lt;<A HREF="http://bitfury.com/content/5-white-papers-research/whitepaper_flare_an_approach_to_routing_in_lightning_network_7_7_2016.pdf">http://bitfury.com/content/5-white-papers-research/whitepaper_flare_an_approach_to_routing_in_lightning_network_7_7_2016.pdf</A>&gt;
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I'd like to discuss a near-term approach that can replace the basic
</I>&gt;&gt;<i> flood-the-network style route discovery, but isn't so complicated that it
</I>&gt;&gt;<i> needs a ton of study and work. This won't be the end-all solution to route
</I>&gt;&gt;<i> discovery, but should take us a lot further than flood-the-network.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I propose a protocol where each node knows about its own local network
</I>&gt;&gt;<i> topology, and to find a final route, a transaction originator queries a
</I>&gt;&gt;<i> number of its connections for routes to the intended destination. By doing
</I>&gt;&gt;<i> this, it means that nodes are *not* receiving or storing the entire network
</I>&gt;&gt;<i> topology, which makes route discovery a lot less taxing on the network (in
</I>&gt;&gt;<i> terms of bandwidth and storage space).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> To go into more detail...
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> When a node joins the network:
</I>&gt;&gt;<i> 1. it broadcasts its information to all its channels (pretty much as
</I>&gt;&gt;<i> proposed here
</I>&gt;&gt;<i> &lt;<A HREF="https://github.com/lightningnetwork/lightning-rfc/blob/master/07-routing-gossip.md">https://github.com/lightningnetwork/lightning-rfc/blob/master/07-routing-gossip.md</A>&gt;)
</I>&gt;&gt;<i> announcing its relevant channel information
</I>&gt;&gt;<i> 2. it requests local network topology information from all its channels
</I>&gt;&gt;<i> for information about channels 1 hop beyond its direct connection (ie it
</I>&gt;&gt;<i> will receive information about which addresses those channels are connected
</I>&gt;&gt;<i> to, and their related fee info / etc)
</I>&gt;&gt;<i> 3. it then requests topology information for channels 2 hops beyond, etc
</I>&gt;&gt;<i> until it has filled its cache to its satisfaction (the user can choose some
</I>&gt;&gt;<i> amount of megabytes as its limit of network topology data to store)
</I>&gt;&gt;<i> 4. it also subscribes to topology changes for nodes at those distances
</I>&gt;&gt;<i> (eg if a node has requested information from 3 hops away, it will receive
</I>&gt;&gt;<i> info about any new channels or removed channels that fall within that
</I>&gt;&gt;<i> distance)
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> When a node receives an announcement message from a node joining the
</I>&gt;&gt;<i> network:
</I>&gt;&gt;<i> 1. it will store that node's info in its cache
</I>&gt;&gt;<i> 2. it will also forward that info to any node that's subscribed to
</I>&gt;&gt;<i> topology changes that fall within the relevant distance
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> When a node wants to construct a route for a transaction:
</I>&gt;&gt;<i> 1. It checks to see if it has a path to that node in its cache. If it
</I>&gt;&gt;<i> does, it finds the cost of the cheapest path it has.
</I>&gt;&gt;<i> 2. It asks all the channels on the edge of its cached local view for
</I>&gt;&gt;<i> their cheapest path (however you want to define cheapest), specifying that
</I>&gt;&gt;<i> it only care about paths with a maximum cost of the cheapest path it has
</I>&gt;&gt;<i> already found in its cache. For example, if the node has nodes up to 3 hops
</I>&gt;&gt;<i> away in its cache, it will *only* ask the nodes 3 hops away (it will not
</I>&gt;&gt;<i> ask its direct connections, nor nodes 2 hops away, since it already has
</I>&gt;&gt;<i> enough information to ignore them)
</I>&gt;&gt;<i> 3. When it gets all its responses, it constructs a path
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> When a node receives a path request from a node:
</I>&gt;&gt;<i> 1. It checks its cache for its cheapest cache-only path
</I>&gt;&gt;<i> 2. It asks nodes on the edge of its cached local view for their cheapest
</I>&gt;&gt;<i> path, specifying that it only cares about paths with a maximum cost of
</I>&gt;&gt;<i> either its cheapest cache-only path or the max-cost specified by the
</I>&gt;&gt;<i> requesting node minus the channel cost between it and the requesting node
</I>&gt;&gt;<i> (whichever is cheaper). A node on the edge of its cached local view is
</I>&gt;&gt;<i> *not* asked for route information if the cost to that node exceeds the
</I>&gt;&gt;<i> max-cost this relay node would specify.
</I>&gt;&gt;<i> 3. It reports the results that satisfy the max-cost requirements of the
</I>&gt;&gt;<i> requesting node
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> And that's it. All the route information can be encrypted and signed so
</I>&gt;&gt;<i> relaying nodes can't read the information inside, and so the requesting
</I>&gt;&gt;<i> source node can verify which nodes sent that information.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> This protocol should keep both node-announcement messages *and* route
</I>&gt;&gt;<i> request messages highly localized.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Thoughts?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> ~BT
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;<i> Lightning-dev mailing list
</I>&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">Lightning-dev at lists.linuxfoundation.org</A>
</I>&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev</A>
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20170904/46ed51f1/attachment.html">http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20170904/46ed51f1/attachment.html</A>&gt;
</PRE>




<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000758.html">[Lightning-dev] Route finding and route generation
</A></li>
	<LI>Next message: <A HREF="000760.html">[Lightning-dev] [MINUTES] Dev Meeting 2017-09-04
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#759">[ date ]</a>
              <a href="thread.html#759">[ thread ]</a>
              <a href="subject.html#759">[ subject ]</a>
              <a href="author.html#759">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">More information about the Lightning-dev
mailing list</a><br>
</body></html>
