<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Lightning-dev] [BOLT Draft] Onion Routing Spec
   </TITLE>
   <LINK REL="Index" HREF="https://lists.linuxfoundation.org/pipermail/lightning-dev/2016-August/index.html" >
   <LINK REL="made" HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20%5BBOLT%20Draft%5D%20Onion%20Routing%20Spec&In-Reply-To=%3CCALxbBHUR1Z1O%2B95FifnAAo1P8W1D5qGJs_X%3DjDEeaJjNBLT72w%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000589.html">
   <LINK REL="Next"  HREF="000559.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Lightning-dev] [BOLT Draft] Onion Routing Spec</H1>
    <B>Christian Decker</B> 
    <A HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20%5BBOLT%20Draft%5D%20Onion%20Routing%20Spec&In-Reply-To=%3CCALxbBHUR1Z1O%2B95FifnAAo1P8W1D5qGJs_X%3DjDEeaJjNBLT72w%40mail.gmail.com%3E"
       TITLE="[Lightning-dev] [BOLT Draft] Onion Routing Spec">decker.christian at gmail.com
       </A><BR>
    <I>Thu Aug  4 17:05:04 UTC 2016</I>
    <P><UL>
        <LI>Previous message: <A HREF="000589.html">[Lightning-dev] [BOLT Draft] Onion Routing Spec
</A></li>
        <LI>Next message: <A HREF="000559.html">[Lightning-dev] [BOLT Draft] Onion Routing Spec
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#561">[ date ]</a>
              <a href="thread.html#561">[ thread ]</a>
              <a href="subject.html#561">[ subject ]</a>
              <a href="author.html#561">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Sending to the mailing list since Laolu pointed out I only sent my reply to
him. Sorry for that.

On Sat, Jul 30, 2016, 15:25 Christian Decker &lt;<A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">decker.christian at gmail.com</A>&gt;
wrote:

&gt;<i> On Wed, Jul 27, 2016 at 8:14 PM Olaoluwa Osuntokun &lt;<A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">laolu32 at gmail.com</A>&gt;
</I>&gt;<i> wrote:
</I>&gt;<i>
</I>&gt;&gt;<i> Hi Christian, welcome to the mailing list!
</I>&gt;&gt;<i>
</I>&gt;<i> Hi Laolu,
</I>&gt;<i>
</I>&gt;<i> glad to be here :-)
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Excellent work! I've been meaning to re-visit my implementation since I
</I>&gt;&gt;<i> finished it last October but have been busy tending to other lnd related
</I>&gt;&gt;<i> items.
</I>&gt;&gt;<i> Thanks for the cleanups and optimizations you've added to my initial
</I>&gt;&gt;<i> Sphinx
</I>&gt;&gt;<i> implementation. Once we've finished fleshing out the initial
</I>&gt;&gt;<i> specification, I'd
</I>&gt;&gt;<i> be happy to get those changes merged!
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I've taken a look at the diff against the existing implementation, plus
</I>&gt;&gt;<i> the
</I>&gt;&gt;<i> current spec draft. I'd say the current spec draft is the *clearest*
</I>&gt;&gt;<i> description of Sphinx I've encountered, especially the padding bits. IMO,
</I>&gt;&gt;<i> the
</I>&gt;&gt;<i> notation within the paper describing how to construct+process the
</I>&gt;&gt;<i> mix-header is
</I>&gt;&gt;<i> rather opaque.
</I>&gt;&gt;<i>
</I>&gt;<i> Actually, your implementation helped a lot in getting a clear picture of
</I>&gt;<i> how Sphinx is supposed to work, so thanks for taking the time to implement
</I>&gt;<i> the paper in the first place. Glad you like my writeup, hopefully it is as
</I>&gt;<i> clear to new implementors as well :-)
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I see you've modified the encryption scheme of the end-to-end payload,
</I>&gt;&gt;<i> switching from the arbitrary block-size block cipher (LIONESS) to purely a
</I>&gt;&gt;<i> stream cipher (ChaCha20). Initially I was under the impression that this
</I>&gt;&gt;<i> might
</I>&gt;&gt;<i> compromise one of the security arguments of the scheme, but on closer
</I>&gt;&gt;<i> inspection this is perfectly fine if one extends the header MAC to the
</I>&gt;&gt;<i> entire
</I>&gt;&gt;<i> payload as you've done. If one was staying true to the original
</I>&gt;&gt;<i> construction,
</I>&gt;&gt;<i> then this would eliminate the possibility of Single-Use Reply Blocks
</I>&gt;&gt;<i> (SURB's)
</I>&gt;&gt;<i> since the sender would be unable to construct the reply mix-header as she
</I>&gt;&gt;<i> would
</I>&gt;&gt;<i> be unaware of they responder's message. It's clear to me now that a MAC
</I>&gt;&gt;<i> covering
</I>&gt;&gt;<i> the end-to-end payload was omitted in the original version since the
</I>&gt;&gt;<i> proof of
</I>&gt;&gt;<i> computational indistinguishability of replies vs responses depends on the
</I>&gt;&gt;<i> structure+processing being identical for both messages types. However I
</I>&gt;&gt;<i> don't
</I>&gt;&gt;<i> see us having any use for SURB's so this is an excellent change.
</I>&gt;&gt;<i> Additionally,
</I>&gt;&gt;<i> modifications to the end-to-end payload will instantly cause packet
</I>&gt;&gt;<i> corruption,
</I>&gt;&gt;<i> stopping invalid packets from propagating through the network.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> I'm going back and forth about including the payloads in the header HMAC.
</I>&gt;<i> I think we have three options here:
</I>&gt;<i>
</I>&gt;<i>  1) Include the payload in the header HMAC computation
</I>&gt;<i>  2) Include an additional set of HMACs for the payload that can be checked
</I>&gt;<i> at each hop
</I>&gt;<i>  3) Just use an encryption scheme that also verifies the integrity, e.g.,
</I>&gt;<i> ChaCha20-Poly1305, on the last hop and normal ChaCha20 on all preceeding
</I>&gt;<i> hops.
</I>&gt;<i>
</I>&gt;<i> The first option is small, and it discards tampered packets as soon as the
</I>&gt;<i> next hop checks its HMAC. The downside is indeed that we lose a lot of
</I>&gt;<i> flexibility. Besides losing the ability to provide a SURB to the final
</I>&gt;<i> recipient, we also lose the ability to do anonymous rendezvous meetings,
</I>&gt;<i> where the final recipient provides half of the route in the form of a
</I>&gt;<i> precompiled header (something that Hornet is using).
</I>&gt;<i>
</I>&gt;<i> The second option is quite costly just to have the drop-early feature. It
</I>&gt;<i> would add 400 bytes to each packet, assuming 20 byte HMACs and 20 hops. On
</I>&gt;<i> the other hand forwarding a packet to the final recipient when we could
</I>&gt;<i> discard it early is quite costly since each hop locks up some funds in the
</I>&gt;<i> form of an associated HTLC.
</I>&gt;<i>
</I>&gt;<i> The third option is just the case in which we'd forward the packet to the
</I>&gt;<i> final recipient, which can then decide whether the payload was tampered
</I>&gt;<i> with or not. Costly in terms of HTLCs being created and funds being locked
</I>&gt;<i> up, but hopefully they'd be released again immediately.
</I>&gt;<i>
</I>&gt;<i> Both the per-hop checkable schemes, combined with nodes signing the
</I>&gt;<i> packets they forward, would give us the ability to identify misbehaving
</I>&gt;<i> nodes and denounce them: if we receive a packet we check the integrity and
</I>&gt;<i> if it doesn't match then we can prove to others that the node forwarded
</I>&gt;<i> something broken with its signature, or it did not check the packet itself.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;&gt;<i> I really like the addition of the per-hop payload! It's a change to the
</I>&gt;&gt;<i> original construction that I've seriously considered proposing. Such a
</I>&gt;&gt;<i> payload
</I>&gt;&gt;<i> should prove to be very useful in the future for information such as:
</I>&gt;&gt;<i> limits on
</I>&gt;&gt;<i> the per-hop absolute timeout, fee information, etc.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> The addition of a version byte is also very welcome. This'll streamline
</I>&gt;&gt;<i> future
</I>&gt;&gt;<i> modifications we may make to the mix-header format in the future, such as
</I>&gt;&gt;<i> increasing the size of the per-hop payload, or switching to an alternative
</I>&gt;&gt;<i> format to encoding the &quot;next hop&quot; address.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Good idea, the next hop address basically does just have to make sense to
</I>&gt;<i> the node processing the packet, so maybe we can use some form of short tag
</I>&gt;<i> or index to specify which existing channel to use, instead of using the
</I>&gt;<i> globally unique address.
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> The current draft doesn't specify the processor's action in the scenario
</I>&gt;&gt;<i> that
</I>&gt;&gt;<i> they're unable to locate the next hop node within their local routing
</I>&gt;&gt;<i> table.
</I>&gt;&gt;<i> Just to be explicit, I think a final paragraph should be inserted under
</I>&gt;&gt;<i> the
</I>&gt;&gt;<i> &quot;Packet Forwarding&quot; section detailing the abort procedure.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Good catch, I'll amend the spec to specify that unroutable packets are
</I>&gt;<i> dropped and the sender signaled.
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &gt; However, they could easily be made variable should we decide that
</I>&gt;&gt;<i> sending
</I>&gt;&gt;<i> &gt; mostly empty messages is wasteful.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I strongly think we should maintain the size uniformity of the packet
</I>&gt;&gt;<i> throughout processing, changes in payload size between hop can give away
</I>&gt;&gt;<i> information w.r.t a node's position within the route.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> We might want to consider dropping the end-to-end payload altogether
</I>&gt;&gt;<i> though. I
</I>&gt;&gt;<i> can't really think of a clear use case for the e2e payload within our
</I>&gt;&gt;<i> specific
</I>&gt;&gt;<i> application.  That would save us 1k bytes, reducing the size of the full
</I>&gt;&gt;<i> mix-header to 1234 bytes. Accounting for the additional fields within an
</I>&gt;&gt;<i> HTLC
</I>&gt;&gt;<i> &quot;add&quot; message, plus some additional overhead, this should keep us below
</I>&gt;&gt;<i> typical
</I>&gt;&gt;<i> MTU sizes, avoiding fragmentation of HTLC &quot;add&quot; messages.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> There is a tradeoff between small packets and keeping the size uniform. I
</I>&gt;<i> think we could bucketize sizes, e.g., have multiples of 32 bytes or 64
</I>&gt;<i> bytes for the fields, to have packets with similar sized payloads have the
</I>&gt;<i> same packet size. That would allow us to also drop the e2e payload by
</I>&gt;<i> setting a size of 0, and still be able to forward it, should we ever find a
</I>&gt;<i> use for it.
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &gt; This specification is limited to version 0 packets and the structure of
</I>&gt;&gt;<i> &gt; future version may change. The receiving node then splits the packet
</I>&gt;&gt;<i> into its
</I>&gt;&gt;<i> &gt; fields.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Packets with a non-zero version byte should be immediately rejected, as
</I>&gt;&gt;<i> well as
</I>&gt;&gt;<i> packets which aren't *exactly* 2258 bytes (or 1234 bytes if we drop the
</I>&gt;&gt;<i> e2e
</I>&gt;&gt;<i> payload).
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> I don't think we need a size check: the fixed size actually allows us to
</I>&gt;<i> serialize directly on the wire, without a size prefix, so if we read less
</I>&gt;<i> than 2258 bytes then we simply continue reading, if we read more, then we
</I>&gt;<i> crossed a packet boundary and ought to split. But maybe that is mixing
</I>&gt;<i> transport layer and packet specification?
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &gt; The resulting HMAC is compared with the HMAC from the packet. Should the
</I>&gt;&gt;<i> &gt; computed HMAC and the HMAC from the packet differ then the node MUST
</I>&gt;&gt;<i> abort
</I>&gt;&gt;<i> &gt; processing and report a route failure.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Perhaps we should explicitly specify that the HMAC equality check MUST be
</I>&gt;&gt;<i> performed without leaking timing information (constant time comparison)? I
</I>&gt;&gt;<i> can't think of a precise potential vulnerability otherwise since the
</I>&gt;&gt;<i> scheme
</I>&gt;&gt;<i> uses an encrypt-then-MAC construction with a semantically secure
</I>&gt;&gt;<i> encryption
</I>&gt;&gt;<i> scheme. I don't see any clear downsides in specifying that the comparison
</I>&gt;&gt;<i> be
</I>&gt;&gt;<i> made in constant.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> I don't see a chance of this being used either, each secret key used in
</I>&gt;<i> the HMAC computation is used just once. But better be safe than sorry. I'll
</I>&gt;<i> add it to the spec.
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &gt; The sender computes a route {n_1, ..., n_{r-1}, n_r}, where n_1 is a
</I>&gt;&gt;<i> peer of
</I>&gt;&gt;<i> &gt; the sender and n_r is the recipient.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> In order to eliminate ambiguity, I think this should be more explicit,
</I>&gt;&gt;<i> specifying that &quot;n_1&quot; is a *direct neighbor* of the sender
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Amended and clarified that a peer is a direct neighbor in the overlay
</I>&gt;<i> network.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;&gt;<i> &gt; A special HMAC value of 20 0x00 bytes indicates that the currently
</I>&gt;&gt;<i> &gt; processing hop is the intended recipient and that the packet should not
</I>&gt;&gt;<i> be
</I>&gt;&gt;<i> &gt; forwarded. At this point the end-to-end payload is fully decrypted and
</I>&gt;&gt;<i> the
</I>&gt;&gt;<i> &gt; route has terminated.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> It seems that with the current construction, then the &quot;next hop&quot; address
</I>&gt;&gt;<i> will
</I>&gt;&gt;<i> also be zero bytes if a packet processor is the last hop in the route.
</I>&gt;&gt;<i> Alternatively, if the sender is aware that the receiver is actually a
</I>&gt;&gt;<i> &quot;virtual
</I>&gt;&gt;<i> channel&quot;, then an additional address could be used instead of the
</I>&gt;&gt;<i> zero-address
</I>&gt;&gt;<i> to facilitate de-multiplexing at the last hop to the destination virtual
</I>&gt;&gt;<i> channel.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Sounds good, I thought I'd use the HMAC to signal so we still have the
</I>&gt;<i> first 20 bytes free to use, adding a de-multiplexing address might be one
</I>&gt;<i> use.
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &gt; In the pocessing phase the secret is the node's private key...
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Typo here, it should read &quot;In the processing phase...&quot;
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I think two key onion-routing related aspects are under specified within
</I>&gt;&gt;<i> the
</I>&gt;&gt;<i> current draft: replay protection, and key rotation. Although we might
</I>&gt;&gt;<i> want to
</I>&gt;&gt;<i> place details concerning key rotation in a separate document covering the
</I>&gt;&gt;<i> initial routing protocol as the two are closely related.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> First, lets talk replay protection. The current draft specifies that:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &gt; The node MUST keep a log of previously used shared secrets. Should the
</I>&gt;&gt;<i> shared
</I>&gt;&gt;<i> &gt; secret already be in the log it MUST abort processing the packet and
</I>&gt;&gt;<i> report a
</I>&gt;&gt;<i> &gt; route failure, since this is likely a replay attack, otherwise the
</I>&gt;&gt;<i> shared
</I>&gt;&gt;<i> &gt; secret is added to the log
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> This is definitely necessary, however as dictated this would require
</I>&gt;&gt;<i> nodes to
</I>&gt;&gt;<i> allocate a potentially *unbounded* amount of storage to the shared secret
</I>&gt;&gt;<i> &quot;seen&quot; log. I think we can allow nodes to periodically truncate this log
</I>&gt;&gt;<i> by
</I>&gt;&gt;<i> adding an additional session time stamp to the mix-header, either placed
</I>&gt;&gt;<i> directly after the version byte, or within the per-hop payload.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> With this absolute timestamp, each entry within the &quot;seen&quot; log becomes a
</I>&gt;&gt;<i> two-tuple: the shared secret itself, and the corresponding timestamp
</I>&gt;&gt;<i> specified
</I>&gt;&gt;<i> within the mix-header. Before the absolute timestamp has passed, the entry
</I>&gt;&gt;<i> within the log remains, and mix-headers received with duplicated shared
</I>&gt;&gt;<i> secret
</I>&gt;&gt;<i> are rejected. If we enforce an upper bound on the &quot;session lifetime&quot;, then
</I>&gt;&gt;<i> nodes can periodically prune this log, discarding obsolete shared secrets.
</I>&gt;&gt;<i> Once an entry has been pruned, although a node may not know if a shared
</I>&gt;&gt;<i> secret
</I>&gt;&gt;<i> is being duplicated, they can reject expired sessions according to the
</I>&gt;&gt;<i> timestamp achieving a similar affect.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Reasonable session times may be something around 30-minutes to an hour or
</I>&gt;&gt;<i> two.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> With this scheme, I think that we can achieve near perfect replay
</I>&gt;&gt;<i> protection
</I>&gt;&gt;<i> without unbounded storage.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> We have to be careful when using timestamps in the packet as it makes
</I>&gt;<i> individual hops collatable. One solution is again to bucketize timestamps
</I>&gt;<i> included in the packet such that we have enough packets with the same
</I>&gt;<i> timestamps to avoid having an attacker associate individual hops in a
</I>&gt;<i> route. The alternative is to have a blinded timestamp per hop, i.e., in the
</I>&gt;<i> routing info, but that automatically blows the size up to 20x. So my
</I>&gt;<i> proposal would be to include a timestamp rounded up to the closest hour and
</I>&gt;<i> have a sliding window of accepted timestamps of +/- 1 hour, remembering the
</I>&gt;<i> secrets for that period and rejecting anything that is too far in the
</I>&gt;<i> future or too far in the past. The more coarse the bigger the less likely
</I>&gt;<i> an attacker is to guess which packets belong to the same route, but the
</I>&gt;<i> more storage is required on the node's side.
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> On to the second aspect: key rotation. Ignoring the possible time-stamped
</I>&gt;&gt;<i> log
</I>&gt;&gt;<i> solution, the (possibly) only other way to allow nodes to prune their
</I>&gt;&gt;<i> shared
</I>&gt;&gt;<i> secret log is to periodically rotate keys. Once a node rotates a key, it
</I>&gt;&gt;<i> can
</I>&gt;&gt;<i> safely delete its *entire* previous shared secret log, as replay attacks
</I>&gt;&gt;<i> will
</I>&gt;&gt;<i> fail on the HMAC check. Independent of replay attack prevention, key
</I>&gt;&gt;<i> rotation
</I>&gt;&gt;<i> is useful in order to provide a degree of forward secrecy. Without key
</I>&gt;&gt;<i> rotation, when a node is compromised by the adversary (assuming the node
</I>&gt;&gt;<i> keeps
</I>&gt;&gt;<i> *all* prior mix-headers), the adversary learns of the next-node within the
</I>&gt;&gt;<i> route, and also the per-hop payload for the compromised node. With key
</I>&gt;&gt;<i> rotation, assuming the prior keys are deleted, then the adversary is only
</I>&gt;&gt;<i> able
</I>&gt;&gt;<i> to decrypt partially ciphertexts from the current epoch.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> So then a question arises: how do we perform key rotation within the
</I>&gt;&gt;<i> network
</I>&gt;&gt;<i> globally with loose synchronization? I say loose synchronization since if
</I>&gt;&gt;<i> rotations aren't synchronized to a degree, then the payments of source
</I>&gt;&gt;<i> nodes
</I>&gt;&gt;<i> may fail as an intermediate hop is unable to process the packet since it
</I>&gt;&gt;<i> used an
</I>&gt;&gt;<i> obsolete onion key. Therefore published onion keys should come in pairs
</I>&gt;&gt;<i> (with
</I>&gt;&gt;<i> overlapping lifetimes), and also be authenticated by a node's identity
</I>&gt;&gt;<i> key.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> A key rotation scheme might look something like the following:
</I>&gt;&gt;<i>     * A node publishes two keys, along with a block hash of a block
</I>&gt;&gt;<i> beyond a
</I>&gt;&gt;<i>       &quot;safe&quot; re-org distance, and a signature (under the identity pubkey)
</I>&gt;&gt;<i>       covering the advertisement.
</I>&gt;&gt;<i>     * The first key is intended for use until N blocks after the specified
</I>&gt;&gt;<i>       block hash, with nodes switching to the second key afterwards.
</I>&gt;&gt;<i>     * At the N/2 point, the original node publishes a new advertisement
</I>&gt;&gt;<i> with
</I>&gt;&gt;<i>       the second key from the original advertisement listed as the
</I>&gt;&gt;<i> &quot;first&quot; key,
</I>&gt;&gt;<i>       and a new fresh quasi-ephemeral onion key. The original node
</I>&gt;&gt;<i> performs
</I>&gt;&gt;<i>       this rotation at intervals at the mid-point of expiration of the
</I>&gt;&gt;<i> oldest
</I>&gt;&gt;<i>       key.
</I>&gt;&gt;<i>     * Nodes who receive this new advertisement (aware of the previous)
</I>&gt;&gt;<i> record
</I>&gt;&gt;<i>       this as the node's next rotation key. Nodes who receive this
</I>&gt;&gt;<i>       advertisement, unaware of the previous treat this as the node's
</I>&gt;&gt;<i> initial
</I>&gt;&gt;<i>       pair of quasi-ephemeral onion keys.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> With this scheme, rotations are synchronized very loosely, perhaps in the
</I>&gt;&gt;<i> timespan of half-days, days, etc. There is a new cost however, when
</I>&gt;&gt;<i> processing
</I>&gt;&gt;<i> packets, a node must attempt to derive the shared secret with both active
</I>&gt;&gt;<i> onion
</I>&gt;&gt;<i> keys. Alternatively, instead of block hashes, we can use some other time
</I>&gt;&gt;<i> based
</I>&gt;&gt;<i> beacon as a switch over point in order to accommodate peers on multiple
</I>&gt;&gt;<i> blockchains.
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> I like the loosely synched approach very much, but do we need explicit
</I>&gt;<i> announcements at all? We could just use the announced key, i.e., the one
</I>&gt;<i> that participated in the channel setup, as a root key for HD key
</I>&gt;<i> derivation. The derivation path could then be based on floor(blockheight /
</I>&gt;<i> 144) so that we rotate keys every day, and don't need any additional
</I>&gt;<i> communication to announce new public keys. The switchover can be a bit
</I>&gt;<i> messy, but we could just accept both old and new keys for a period around
</I>&gt;<i> switchover and try both, or add the date in the packet, which would anyway
</I>&gt;<i> be common to all packets on that day.
</I>&gt;<i>
</I>&gt;<i> A downside of using HD key derivation is that, should the root key be
</I>&gt;<i> compromised then we cannot switch keys to new ones without a teardown, but
</I>&gt;<i> in that case we'd be in a world of pain anyway since these keys allow
</I>&gt;<i> spending the node's coins :-) Not adding the date allows us to switch keys
</I>&gt;<i> quicker and each node could announce its own rotation period, to keep local
</I>&gt;<i> storage low, but it adds some more computation as we determine the intended
</I>&gt;<i> public key by trial and error.
</I>&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I'll take a few more passes through the current draft spec, as well are
</I>&gt;&gt;<i> your
</I>&gt;&gt;<i> commits in your fork of my original implementation, following up with any
</I>&gt;&gt;<i> other
</I>&gt;&gt;<i> questions/comments.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I'm also trying to figure out how to enable intermediate nodes to reply
</I>&gt;<i> to a packet, e.g., if capacities are insufficient or the next node is
</I>&gt;<i> unreachable, by recycling the routing info. Currently we'd probably forward
</I>&gt;<i> reply along the HTLC path associated with the forward path over the
</I>&gt;<i> encrypted channel.
</I>&gt;<i>
</I>&gt;<i> So far I had no luck trying to build a return path into the header while
</I>&gt;<i> forwarding. Maybe we could continue blinding the ephemeral key on the
</I>&gt;<i> return path, and have a mechanism to tell the node the total blinding
</I>&gt;<i> factor along the path so that it can encrypt something in the routing info
</I>&gt;<i> for the return path? That would neatly combine Hornet and Sphinx,
</I>&gt;<i> eliminating the initial roundtrip to setup forwarding segments.
</I>&gt;<i>
</I>&gt;<i> Thanks again for the detailed feedback, looking forward to read your
</I>&gt;<i> thoughts on this :-)
</I>&gt;<i>
</I>&gt;<i> Cheers,
</I>&gt;<i> Christian
</I>&gt;<i>
</I>&gt;<i> -- Laolu
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> On Mon, Jul 25, 2016 at 9:23 AM Christian Decker &lt;
</I>&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">decker.christian at gmail.com</A>&gt; wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Hi all,
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I took the liberty of taking apart Olaoluwa's Sphinx implementation and
</I>&gt;&gt;&gt;<i> I came up with a spec draft that I'd like to propose [1]. It should roughly
</I>&gt;&gt;&gt;<i> be Sphinx, pinning down the various key-generation and stream generation
</I>&gt;&gt;&gt;<i> algorithms, and adding a per-hop payload.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The per-hop payload is used to give instructions to individual hops,
</I>&gt;&gt;&gt;<i> i.e., how many coins to forward to the next hop. This means that the
</I>&gt;&gt;&gt;<i> end-to-end payload, i.e., the message in the Sphinx protocol, is currently
</I>&gt;&gt;&gt;<i> unused and could be omitted.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The payloads are currently fixed size (20 bytes per-hop and 1024 bytes
</I>&gt;&gt;&gt;<i> for end-to-end payload) to avoid making messages collatable by their size.
</I>&gt;&gt;&gt;<i> However, they could easily be made variable should we decide that
</I>&gt;&gt;&gt;<i> sending mostly empty messages is wasteful.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The spec is implemented in Go [2] and in C [3]. The Go version is an
</I>&gt;&gt;&gt;<i> adaptation of Olaoluwa's implementation, with some minor speedups, removing
</I>&gt;&gt;&gt;<i> some duplicate information, stripping the header, and switching to ChaCha20
</I>&gt;&gt;&gt;<i> for stream generation and encryption. I also added a small commandline tool
</I>&gt;&gt;&gt;<i> that allows you to write packets to stdout so that we can feed an onion
</I>&gt;&gt;&gt;<i> generated by the C version to the Go implementation and vice-versa :-)
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Feedback is very welcome. If people like the draft I'll create
</I>&gt;&gt;&gt;<i> pull-requests for the spec and the implementations, but I'd like to keep
</I>&gt;&gt;&gt;<i> the discussion on the mailing list :-)
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Cheers,
</I>&gt;&gt;&gt;<i> Christian
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> [1]
</I>&gt;&gt;&gt;<i> <A HREF="https://github.com/cdecker/lightning-rfc/blob/master/bolts/onion-protocol.md">https://github.com/cdecker/lightning-rfc/blob/master/bolts/onion-protocol.md</A>
</I>&gt;&gt;&gt;<i> [2] <A HREF="https://github.com/cdecker/lightning-onion/tree/chacha20">https://github.com/cdecker/lightning-onion/tree/chacha20</A>
</I>&gt;&gt;&gt;<i> [3] <A HREF="https://github.com/cdecker/lightning/tree/chacha20">https://github.com/cdecker/lightning/tree/chacha20</A>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;&gt;<i> Lightning-dev mailing list
</I>&gt;&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">Lightning-dev at lists.linuxfoundation.org</A>
</I>&gt;&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev</A>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160804/23e60f7a/attachment-0001.html">http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20160804/23e60f7a/attachment-0001.html</A>&gt;
</PRE>















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000589.html">[Lightning-dev] [BOLT Draft] Onion Routing Spec
</A></li>
	<LI>Next message: <A HREF="000559.html">[Lightning-dev] [BOLT Draft] Onion Routing Spec
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#561">[ date ]</a>
              <a href="thread.html#561">[ thread ]</a>
              <a href="subject.html#561">[ subject ]</a>
              <a href="author.html#561">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">More information about the Lightning-dev
mailing list</a><br>
</body></html>
