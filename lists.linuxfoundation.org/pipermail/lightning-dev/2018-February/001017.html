<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
   </TITLE>
   <LINK REL="Index" HREF="https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/index.html" >
   <LINK REL="made" HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20AMP%3A%20Atomic%20Multi-Path%20Payments%20over%20Lightning&In-Reply-To=%3CCAFDmaN44qv%3DxtuBTEcsQWfXW5aFy1Ms4fTBTofdzM7VMtagTUw%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001015.html">
   <LINK REL="Next"  HREF="001019.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning</H1>
    <B>Cezary Dziemian</B> 
    <A HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20AMP%3A%20Atomic%20Multi-Path%20Payments%20over%20Lightning&In-Reply-To=%3CCAFDmaN44qv%3DxtuBTEcsQWfXW5aFy1Ms4fTBTofdzM7VMtagTUw%40mail.gmail.com%3E"
       TITLE="[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning">cezary.dziemian at gmail.com
       </A><BR>
    <I>Sun Feb 11 13:58:49 UTC 2018</I>
    <P><UL>
        <LI>Previous message: <A HREF="001015.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
        <LI>Next message: <A HREF="001019.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1017">[ date ]</a>
              <a href="thread.html#1017">[ thread ]</a>
              <a href="subject.html#1017">[ subject ]</a>
              <a href="author.html#1017">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>That would be great improvement, if AMP could work this way:

1. I would like to send 0.1 BTC, so I split this to 5 payment 0.02 BTC each
+ one extra 0.02 BTC payment.
2. When recipient received 6 htlcs, he is able to spend only 5 of them.
If recipient receives, only 5 of them, it is still fine, and payment is
success.

In such scenario, single route/payment would fail, and payment as whole
would still be success. Do you think that would be possible? It could
greatly increase reliability of LN payments.

2018-02-09 11:15 GMT+01:00 CJP &lt;<A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">cjp at ultimatestunts.nl</A>&gt;:

&gt;<i> Can you give a use case for this?
</I>&gt;<i>
</I>&gt;<i> Usually, especially in the common case that a payment is done in
</I>&gt;<i> exchange for some non-cryptographic asset (e.g. physical goods), there
</I>&gt;<i> already is some kind of trust between payer and payee. So, if a payment
</I>&gt;<i> is split non-atomically into smaller transactions, and only a part
</I>&gt;<i> succeeds, presumably they can cooperatively figure out some way to
</I>&gt;<i> settle the situation.
</I>&gt;<i>
</I>&gt;<i> I spoke to people of the &quot;interledger&quot; project, and what they are
</I>&gt;<i> planning to do is to non-atomically split *every* transaction into lots
</I>&gt;<i> of micro-payments. In fact, they consider it unnecessary to enforce
</I>&gt;<i> HTLCs with scripts, because their amounts are so small(*). If one
</I>&gt;<i> micro-payment fails, that just makes them learn that a certain channel
</I>&gt;<i> is unreliable, and they'll send further payments (and even the remaining
</I>&gt;<i> part of the same payment) through a different route.
</I>&gt;<i>
</I>&gt;<i> CJP
</I>&gt;<i>
</I>&gt;<i> (*) not worth the extra on-blockchain fee due to the increased tx size.
</I>&gt;<i>
</I>&gt;<i> Olaoluwa Osuntokun schreef op di 06-02-2018 om 05:26 [+0000]:
</I>&gt;<i> &gt; Hi Y'all,
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; A common question I've seen concerning Lightning is: &quot;I have five $2
</I>&gt;<i> &gt; channels, is it possible for me to *atomically* send $6 to fulfill a
</I>&gt;<i> &gt; payment?&quot;. The answer to this question is &quot;yes&quot;, provided that the
</I>&gt;<i> &gt; receiver
</I>&gt;<i> &gt; waits to pull all HTLC's until the sum matches their invoice.
</I>&gt;<i> &gt; Typically, one
</I>&gt;<i> &gt; assumes that the receiver will supply a payment hash, and the sender
</I>&gt;<i> &gt; will
</I>&gt;<i> &gt; re-use the payment hash for all streams. This has the downside of
</I>&gt;<i> &gt; payment
</I>&gt;<i> &gt; hash re-use across *multiple* payments (which can already easily be
</I>&gt;<i> &gt; correlated), and also has a failure mode where if the sender fails to
</I>&gt;<i> &gt; actually satisfy all the payment flows, then the receiver can still
</I>&gt;<i> &gt; just
</I>&gt;<i> &gt; pull the monies (and possibly not disperse a service, or w/e).
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Conner Fromknecht and I have come up with a way to achieve this over
</I>&gt;<i> &gt; Lightning while (1) not re-using any payment hashes across all payment
</I>&gt;<i> &gt; flows, and (2) adding a *strong* guarantee that the receiver won't be
</I>&gt;<i> &gt; paid
</I>&gt;<i> &gt; until *all* partial payment flows are extended. We call this scheme
</I>&gt;<i> &gt; AMP
</I>&gt;<i> &gt; (Atomic Multi-path Payments). It can be experimented with on Lightning
</I>&gt;<i> &gt; *today* with the addition of a new feature bit to gate this new
</I>&gt;<i> &gt; feature. The beauty of the scheme is that it requires no fundamental
</I>&gt;<i> &gt; changes
</I>&gt;<i> &gt; to the protocol as is now, as the negotiation is strictly *end-to-end*
</I>&gt;<i> &gt; between sender and receiver.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; TL;DR: we repurpose some unused space in the onion per-hop payload of
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; onion blob to signal our protocol (and deliver some protocol-specific
</I>&gt;<i> &gt; data),
</I>&gt;<i> &gt; then use additive secret sharing to ensure that the receiver can't
</I>&gt;<i> &gt; pull the
</I>&gt;<i> &gt; payment until they have enough shares to reconstruct the original
</I>&gt;<i> &gt; pre-image.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Protocol Goals
</I>&gt;<i> &gt; ==============
</I>&gt;<i> &gt; 1. Atomicity: The logical transaction should either succeed or fail in
</I>&gt;<i> &gt; entirety. Naturally, this implies that the receiver should not be
</I>&gt;<i> &gt; unable to
</I>&gt;<i> &gt; settle *any* of the partial payments, until all of them have arrived.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; 2. Avoid Payment Hash Reuse: The payment preimages validated by the
</I>&gt;<i> &gt; consensus layer should be distinct for each partial payment.
</I>&gt;<i> &gt; Primarily,
</I>&gt;<i> &gt; this helps avoid correlation of the partial payments, and ensures that
</I>&gt;<i> &gt; malicious intermediaries straddling partial payments cannot steal
</I>&gt;<i> &gt; funds.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; 3. Order Invariance: The protocol should be forgiving to the order in
</I>&gt;<i> &gt; which
</I>&gt;<i> &gt; partial payments arrive at the destination, adding robustness in the
</I>&gt;<i> &gt; face of
</I>&gt;<i> &gt; delays or routing failures.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; 4. Non-interactive Setup: It should be possible for the sender to
</I>&gt;<i> &gt; perform an
</I>&gt;<i> &gt; AMP without directly coordinating with the receiving node.
</I>&gt;<i> &gt; Predominantly,
</I>&gt;<i> &gt; this means that the *sender* is able to determine the number of
</I>&gt;<i> &gt; partial
</I>&gt;<i> &gt; payments to use for a particular AMP, which makes sense since they
</I>&gt;<i> &gt; will be
</I>&gt;<i> &gt; the one fronting the fees for the cost of this parameter. Plus, we can
</I>&gt;<i> &gt; always turn a non-interactive protocol into an interactive one for the
</I>&gt;<i> &gt; purposes of invoicing.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Protocol Benefits
</I>&gt;<i> &gt; =================
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Sending pay payments predominantly over an AMP-like protocol has
</I>&gt;<i> &gt; several
</I>&gt;<i> &gt; clear benefits:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - Eliminates the constraint that a single path from sender to
</I>&gt;<i> &gt; receiver
</I>&gt;<i> &gt;     with sufficient directional capacity. This reduces the pressure to
</I>&gt;<i> &gt; have
</I>&gt;<i> &gt;     larger channels in order to support larger payment flows. As a
</I>&gt;<i> &gt; result,
</I>&gt;<i> &gt;     the payment graph be very diffused, without sacrificing payment
</I>&gt;<i> &gt;     utility
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - Reduces strain from larger payments on individual paths, and
</I>&gt;<i> &gt; allows the
</I>&gt;<i> &gt;     liquidity imbalances to be more diffuse. We expect this to have a
</I>&gt;<i> &gt;     non-negligible impact on channel longevity. This is due to the
</I>&gt;<i> &gt; fact that
</I>&gt;<i> &gt;     with usage of AMP, payment flows are typically *smaller* meaning
</I>&gt;<i> &gt; that
</I>&gt;<i> &gt;     each payment will unbalance a channel to a lesser degree that
</I>&gt;<i> &gt;     with one giant flow.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - Potential fee savings for larger payments, contingent on there
</I>&gt;<i> &gt; being a
</I>&gt;<i> &gt;     super-linear component to routed fees. It's possible that with
</I>&gt;<i> &gt;     modifications to the fee schedule, it's actually *cheaper* to send
</I>&gt;<i> &gt;     payments over multiple flows rather than one giant flow.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - Allows for logical payments larger than the current maximum value
</I>&gt;<i> &gt; of an
</I>&gt;<i> &gt;     individual payment. Atm we have a (temporarily) limit on the max
</I>&gt;<i> &gt; payment
</I>&gt;<i> &gt;     size. With AMP, this can be side stepped as each flow can be up
</I>&gt;<i> &gt; the max
</I>&gt;<i> &gt;     size, with the sum of all flows exceeding the max.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - Given sufficient path diversity, AMPs may improve the privacy of
</I>&gt;<i> &gt; LN
</I>&gt;<i> &gt;     Intermediaries are now unaware to how much of the total payment
</I>&gt;<i> &gt; they are
</I>&gt;<i> &gt;     forwarding, or even if they are forwarding a partial payment at
</I>&gt;<i> &gt; all.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - Using smaller payments increases the set of possible paths a
</I>&gt;<i> &gt; partial
</I>&gt;<i> &gt;     payment could have taken, which reduces the effectiveness of
</I>&gt;<i> &gt; static
</I>&gt;<i> &gt;     analysis techniques involving channel capacities and the plaintext
</I>&gt;<i> &gt;     values being forwarded.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Protocol Overview
</I>&gt;<i> &gt; ==================
</I>&gt;<i> &gt; This design can be seen as a generalization of the single,
</I>&gt;<i> &gt; non-interactive
</I>&gt;<i> &gt; payment scheme, that uses decoding of extra onion blobs (EOBs?) to
</I>&gt;<i> &gt; encode
</I>&gt;<i> &gt; extra data for the receiver. In that design, the extra data includes a
</I>&gt;<i> &gt; payment preimage that the receiver can use to settle back the payment.
</I>&gt;<i> &gt; EOBs
</I>&gt;<i> &gt; and some method of parsing them are really the only requirement for
</I>&gt;<i> &gt; this
</I>&gt;<i> &gt; protocol to work. Thus, only the sender and receiver need to implement
</I>&gt;<i> &gt; this
</I>&gt;<i> &gt; feature in order for it to function, which can be announced using a
</I>&gt;<i> &gt; feature
</I>&gt;<i> &gt; bit.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; First, let's review the current format of the per-hop payload for each
</I>&gt;<i> &gt; node
</I>&gt;<i> &gt; described in BOLT-0004.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;
</I>&gt;<i> &#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
</I>&gt;<i> &gt; &#9474;Realm (1 byte) &#9474;Next Addr (8 bytes)&#9474;Amount (8 bytes)&#9474;Outgoing CLTV (4
</I>&gt;<i> &gt; bytes)&#9474;Unused (12 bytes)&#9474; HMAC (32 bytes) &#9474;
</I>&gt;<i> &gt; &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;
</I>&gt;<i> &#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
</I>&gt;<i> &gt; &#9632;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;
</I>&gt;<i> &#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9632;
</I>&gt;<i> &gt;                                               &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
</I>&gt;<i> &gt;                                               &#9474;65 Bytes Per Hop &#9474;
</I>&gt;<i> &gt;                                               &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Currently, *each* node gets a 65-byte payload. We use this payload to
</I>&gt;<i> &gt; give
</I>&gt;<i> &gt; each node instructions on *how* to forward a payment. We tell each
</I>&gt;<i> &gt; node: the
</I>&gt;<i> &gt; realm (or chain to forward on), then next node to forward to, the
</I>&gt;<i> &gt; amount to
</I>&gt;<i> &gt; forward (this is where fees are extracted by forwarding out less than
</I>&gt;<i> &gt; in),
</I>&gt;<i> &gt; the outgoing CLTV (allows verification that the prior node didn't
</I>&gt;<i> &gt; modify any
</I>&gt;<i> &gt; values), and finally an HMAC over the entire thing.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Two important points:
</I>&gt;<i> &gt;   1. We have 12 bytes for each hop that are currently unpurposed and
</I>&gt;<i> &gt; can be
</I>&gt;<i> &gt;   used by application protocols to signal new interpretation of bytes
</I>&gt;<i> &gt; and
</I>&gt;<i> &gt;   also deliver additional encrypted+authenticated data to *each* hop.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   2. The protocol currently has a hard limit of 20-hops. With this
</I>&gt;<i> &gt; feature
</I>&gt;<i> &gt;   we ensure that the packet stays fixed sized during processing in
</I>&gt;<i> &gt; order to
</I>&gt;<i> &gt;   avoid leaking positional information. Typically most payments won't
</I>&gt;<i> &gt; use
</I>&gt;<i> &gt;   all 20 hops, as a result, we can use the remaining hops to stuff in
</I>&gt;<i> &gt; *even
</I>&gt;<i> &gt;   more* data.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Protocol Description
</I>&gt;<i> &gt; ====================
</I>&gt;<i> &gt; The solution we propose is Atomic Multi-path Payments (AMPs). At a
</I>&gt;<i> &gt; high
</I>&gt;<i> &gt; level, this leverages EOBs to deliver additive shares of a base
</I>&gt;<i> &gt; preimage,
</I>&gt;<i> &gt; from which the payment preimages of partial payments can be derived.
</I>&gt;<i> &gt; The
</I>&gt;<i> &gt; receiver can only construct this value after having received all of
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; partial payments, satisfying the atomicity constraint.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The basic protocol:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Primitives
</I>&gt;<i> &gt; ==========
</I>&gt;<i> &gt; Let H be a CRH function.
</I>&gt;<i> &gt; Let || denote concatenation.
</I>&gt;<i> &gt; Let ^ denote xor.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Sender Requirements
</I>&gt;<i> &gt; ===================
</I>&gt;<i> &gt; The parameters to the sending procedure are a random identifier ID,
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; number of partial payments n, and the total payment value V. Assume
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; sender has some way of dividing V such that V = v_1 + &#8230; + v_n.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; To begin, the sender builds the base preimage BP, from which n partial
</I>&gt;<i> &gt; preimages will be derived. Next, the sender samples n additive shares
</I>&gt;<i> &gt; s_1,
</I>&gt;<i> &gt; &#8230;, s_n, and takes the sum to compute BP = s_1 ^ &#8230; ^ s_n.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; With the base preimage created, the sender now moves on to
</I>&gt;<i> &gt; constructing the
</I>&gt;<i> &gt; n partial payments. For each i in [1,n], the sender deterministically
</I>&gt;<i> &gt; computes the partial preimage r_i = H(BP ||  i), by concatenating the
</I>&gt;<i> &gt; sequence number i to the base preimage and hashing the result.
</I>&gt;<i> &gt; Afterwards,
</I>&gt;<i> &gt; it applies H to determine the payment hash to use in the i&#8217;th partial
</I>&gt;<i> &gt; payment as h_i = H(r_i). Note that that with this preimage derivation
</I>&gt;<i> &gt; scheme, once the payments are pulled each pre-image is distinct and
</I>&gt;<i> &gt; indistinguishable from any other.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; With all of the pieces in place, the sender initiates the i&#8217;th payment
</I>&gt;<i> &gt; by
</I>&gt;<i> &gt; constructing a route to the destination with value v_i and payment
</I>&gt;<i> &gt; hash h_i.
</I>&gt;<i> &gt; The tuple (ID, n, s_i) is included in the EOB to be opened by the
</I>&gt;<i> &gt; receiver.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; In order to include the three tuple within the per-hop payload for the
</I>&gt;<i> &gt; final
</I>&gt;<i> &gt; destination, we repurpose the _first_ byte of the un-used padding
</I>&gt;<i> &gt; bytes in
</I>&gt;<i> &gt; the payload to signal version 0x01 of the AMP protocol (note this is a
</I>&gt;<i> &gt; PoC
</I>&gt;<i> &gt; outline, we would need to standardize signalling of these 12 bytes to
</I>&gt;<i> &gt; support other protocols). Typically this byte isn't set, so the
</I>&gt;<i> &gt; existence of
</I>&gt;<i> &gt; this means that we're (1) using AMP, and (2) the receiver should
</I>&gt;<i> &gt; consume the
</I>&gt;<i> &gt; _next_ hop as well. So if the payment length is actually 5, the sender
</I>&gt;<i> &gt; tacks
</I>&gt;<i> &gt; on an additional dummy 6th hop, encrypted with the _same_ shared
</I>&gt;<i> &gt; secret for
</I>&gt;<i> &gt; that hop to deliver the e2e encrypted data.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Note, the sender can retry partial payments just as they would normal
</I>&gt;<i> &gt; payments, since they are order invariant, and would be
</I>&gt;<i> &gt; indistinguishable
</I>&gt;<i> &gt; from regular payments to intermediaries in the network.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Receiver Requirements
</I>&gt;<i> &gt; =====================
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Upon the arrival of each partial payment, the receiver will
</I>&gt;<i> &gt; iteratively
</I>&gt;<i> &gt; reconstruct BP, and do some bookkeeping to figure out when to settle
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; partial payments. During this reconstruction process, the receiver
</I>&gt;<i> &gt; does not
</I>&gt;<i> &gt; need to be aware of the order in which the payments were sent, and in
</I>&gt;<i> &gt; fact
</I>&gt;<i> &gt; nothing about the incoming partial payments reveals this information
</I>&gt;<i> &gt; to the
</I>&gt;<i> &gt; receiver, though this can be learned after reconstructing BP.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Each EOB is decoded to retrieve (ID, n, s_i), where i is the unique
</I>&gt;<i> &gt; but
</I>&gt;<i> &gt; unknown index of the incoming partial payment. The receiver has access
</I>&gt;<i> &gt; to
</I>&gt;<i> &gt; persistent key-value store DB that maps ID to (n, c*, BP*), where c*
</I>&gt;<i> &gt; represents the number of partial payments received, BP* is the sum of
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; received additive shares, and the superscript * denotes that the value
</I>&gt;<i> &gt; is
</I>&gt;<i> &gt; being updated iteratively. c* and BP* both have initial values of 0.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; In the basic protocol, the receiver cache&#8217;s the first n it sees, and
</I>&gt;<i> &gt; verifies that all incoming partial payments have the same n. The
</I>&gt;<i> &gt; receiver
</I>&gt;<i> &gt; should reject all partial payments if any EOB deviates.  Next, the we
</I>&gt;<i> &gt; update
</I>&gt;<i> &gt; our persistent store with DB[ID] = (n, c* + 1, BP* ^ s_i), advancing
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; reconstruction by one step.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; If c* + 1 &lt; n, there are still more packets in flight, so we sit
</I>&gt;<i> &gt; tight.
</I>&gt;<i> &gt; Otherwise, the receiver assumes all partial payments have arrived, and
</I>&gt;<i> &gt; can
</I>&gt;<i> &gt; being settling them back. Using the base preimage BP = BP* ^ s_i from
</I>&gt;<i> &gt; our
</I>&gt;<i> &gt; final iteration, the receiver can re-derive all n partial preimages
</I>&gt;<i> &gt; and
</I>&gt;<i> &gt; payment hashes, using r_i = H(BP || i) and h_i = H(r_i) simply through
</I>&gt;<i> &gt; knowledge of n and BP.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Finally, the receiver settles back any outstanding payments that
</I>&gt;<i> &gt; include
</I>&gt;<i> &gt; payment hash h_i using the partial preimage r_i. Each r_i will appear
</I>&gt;<i> &gt; random
</I>&gt;<i> &gt; due to the nature of H, as will it&#8217;s corresponding h_i. Thus, each
</I>&gt;<i> &gt; partial
</I>&gt;<i> &gt; payment should appear uncorrelated, and does not reveal that it is
</I>&gt;<i> &gt; part of
</I>&gt;<i> &gt; an AMP nor the number of partial payments used.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Non-interactive to Interactive AMPs
</I>&gt;<i> &gt; ===================================
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Sender simply receives an ID and amount from the receiver in an
</I>&gt;<i> &gt; invoice
</I>&gt;<i> &gt; before initiating the protocol. The receiver should only consider the
</I>&gt;<i> &gt; invoice settled if the total amount received in partial payments
</I>&gt;<i> &gt; containing
</I>&gt;<i> &gt; ID matches or exceeds the amount specified in the invoice. With this
</I>&gt;<i> &gt; variant, the receiver is able to map all partial payments to a
</I>&gt;<i> &gt; pre-generated
</I>&gt;<i> &gt; invoice statement.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Additive Shares vs Threshold-Shares
</I>&gt;<i> &gt; ===================================
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The biggest reason to use additive shares seems to be atomicity.
</I>&gt;<i> &gt; Threshold
</I>&gt;<i> &gt; shares open the door to some partial payments being settled, even if
</I>&gt;<i> &gt; others
</I>&gt;<i> &gt; are left in flight. Haven&#8217;t yet come up with a good reason for using
</I>&gt;<i> &gt; threshold schemes, but there seem to be plenty against it.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Reconstruction of additive shares can be done iteratively, and is win
</I>&gt;<i> &gt; for
</I>&gt;<i> &gt; the storage and computation requirements on the receiving end. If the
</I>&gt;<i> &gt; sender
</I>&gt;<i> &gt; decides to use fewer than n partial payments, the remaining shares
</I>&gt;<i> &gt; could be
</I>&gt;<i> &gt; included in the EOB of the final partial payment to allow the sender
</I>&gt;<i> &gt; to
</I>&gt;<i> &gt; reconstruct sooner. Sender could also optimistically do partial
</I>&gt;<i> &gt; reconstruction on this last aggregate value.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Adaptive AMPs
</I>&gt;<i> &gt; =============
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The sender may not always be aware of how many partial payments they
</I>&gt;<i> &gt; wish to
</I>&gt;<i> &gt; send at the time of the first partial payment, at which point the
</I>&gt;<i> &gt; simplified
</I>&gt;<i> &gt; protocol would require n to be chosen. To accommodate, the above
</I>&gt;<i> &gt; scheme can
</I>&gt;<i> &gt; be adapted to handle a dynamically chosen n by iteratively
</I>&gt;<i> &gt; constructing the
</I>&gt;<i> &gt; shared secrets as follows.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Starting with a base preimage BP, the key trick is that the sender
</I>&gt;<i> &gt; remember
</I>&gt;<i> &gt; the difference between the base preimage and the sum of all partial
</I>&gt;<i> &gt; preimages used so far. The relation is described using the following
</I>&gt;<i> &gt; equations:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;     X_0 = 0
</I>&gt;<i> &gt;     X_i = X_{i-1} ^ s_i
</I>&gt;<i> &gt;     X_n = BP ^ X_{n-1}
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; where if n=1, X_1 = BP, implying that this is in fact a generalization
</I>&gt;<i> &gt; of
</I>&gt;<i> &gt; the single, non-interactive payment scheme mentioned above. For
</I>&gt;<i> &gt; i=1, ...,
</I>&gt;<i> &gt; n-1, the sender sends s_i in the EOB, and  X_n for the n-th share.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Iteratively reconstructing s_1 ^ &#8230;. ^ s_{n-1} ^ X_n = BP, allows the
</I>&gt;<i> &gt; receiver to compute all relevant r_i = H(BP || i) and h_i = H(r_i).
</I>&gt;<i> &gt; Lastly,
</I>&gt;<i> &gt; the final number of partial payments n could be signaled in the final
</I>&gt;<i> &gt; EOB,
</I>&gt;<i> &gt; which would also serve as a sentinel value for signaling completion.
</I>&gt;<i> &gt; In
</I>&gt;<i> &gt; response to DOS vectors stemming from unknown values of n,
</I>&gt;<i> &gt; implementations
</I>&gt;<i> &gt; could consider advertising a maximum value for n, or adopting some
</I>&gt;<i> &gt; sort of
</I>&gt;<i> &gt; framing pattern for conveying that more partial payments are on the
</I>&gt;<i> &gt; way.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; We can further modify our usage of the per-hop payloads to send
</I>&gt;<i> &gt; (H(BP), s_i) to
</I>&gt;<i> &gt; consume most of the EOB sent from sender to receiver. In this
</I>&gt;<i> &gt; scenario, we'd
</I>&gt;<i> &gt; repurpose the 11-bytes *after* our signalling byte in the unused byte
</I>&gt;<i> &gt; section
</I>&gt;<i> &gt; to store the payment ID (which should be unique for each payment). In
</I>&gt;<i> &gt; the case
</I>&gt;<i> &gt; of a non-interactive payment, this will be unused. While for
</I>&gt;<i> &gt; interactive
</I>&gt;<i> &gt; payments, this will be the ID within the invoice. To deliver this
</I>&gt;<i> &gt; slimmer
</I>&gt;<i> &gt; 2-tuple, we'll use 32-bytes for the hash of the BP, and 32-bytes for
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; partial pre-image share, leaving an un-used byte in the payload.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Cross-Chain AMPs
</I>&gt;<i> &gt; ================
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; AMPs can be used to pay a receiver in multiple currencies
</I>&gt;<i> &gt; atomically...which
</I>&gt;<i> &gt; is pretty cool :D
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Open Research Questions
</I>&gt;<i> &gt; =======================
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The above is a protocol sketch to achieve atomic multi-path payments
</I>&gt;<i> &gt; over
</I>&gt;<i> &gt; Lightning. The details concerning onion blob usage serves as a
</I>&gt;<i> &gt; template that
</I>&gt;<i> &gt; future protocols can draw upon in order to deliver additional data to
</I>&gt;<i> &gt; *any*
</I>&gt;<i> &gt; hop in the route. However, there are still a few open questions before
</I>&gt;<i> &gt; something like this can be feasibly deployed.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; 1. How does the sender decide how many chunked payments to send, and
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt; size of each payment?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - Upon a closer examination, this seems to overlap with the task of
</I>&gt;<i> &gt;     congestion control within TCP. The sender may be able to utilize
</I>&gt;<i> &gt;     inspired heuristics to gauge: (1) how large the initial payment
</I>&gt;<i> &gt; should be
</I>&gt;<i> &gt;     and (2) how many subsequent payments may be required. Note that if
</I>&gt;<i> &gt; the
</I>&gt;<i> &gt;     first payment succeeds, then the exchange is over in a signal
</I>&gt;<i> &gt; round.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; 2. How can AMP and HORNET be composed?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   - If we eventually integrate HORNET, then a distinct communications
</I>&gt;<i> &gt;     sessions can be established to allow the sender+receiver to
</I>&gt;<i> &gt; exchange
</I>&gt;<i> &gt;     up-to-date partial payment information. This may allow the sender
</I>&gt;<i> &gt; to more
</I>&gt;<i> &gt;     accurately size each partial payment.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; 3. Can the sender's initial strategy be governed by an instance of the
</I>&gt;<i> &gt; Push-relabel max flow algo?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; 4. How does this mesh with the current max HTLC limit on a commitment?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;    - ATM, we have a max limit on the number of active HTLC's on a
</I>&gt;<i> &gt; particular
</I>&gt;<i> &gt;      commitment transaction. We do this, as otherwise it's possible
</I>&gt;<i> &gt; that the
</I>&gt;<i> &gt;      transaction is too large, and exceeds standardness w.r.t
</I>&gt;<i> &gt; transaction
</I>&gt;<i> &gt;      size. In a world where most payments use an AMP-like protocol,
</I>&gt;<i> &gt; then
</I>&gt;<i> &gt;      overall ant any given instance there will be several pending
</I>&gt;<i> &gt; HTLC's on
</I>&gt;<i> &gt;      commitments network wise.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;      This may incentivize nodes to open more channels in order to
</I>&gt;<i> &gt; support
</I>&gt;<i> &gt;      the increased commitment space utilization.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Conclusion
</I>&gt;<i> &gt; ==========
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; We've presented a design outline of how to integrate atomic multi-path
</I>&gt;<i> &gt; payments (AMP) into Lightning. The existence of such a construct
</I>&gt;<i> &gt; allows a
</I>&gt;<i> &gt; sender to atomically split a payment flow amongst several individual
</I>&gt;<i> &gt; payment
</I>&gt;<i> &gt; flows. As a result, larger channels aren't as important as it's
</I>&gt;<i> &gt; possible to
</I>&gt;<i> &gt; utilize one total outbound payment bandwidth to send several channels.
</I>&gt;<i> &gt; Additionally, in order to support the increased load, internal routing
</I>&gt;<i> &gt; nodes
</I>&gt;<i> &gt; are incensed have more active channels. The existence of AMP-like
</I>&gt;<i> &gt; payments
</I>&gt;<i> &gt; may also increase the longevity of channels as there'll be smaller,
</I>&gt;<i> &gt; more
</I>&gt;<i> &gt; numerous payment flows, making it unlikely that a single payment comes
</I>&gt;<i> &gt; across unbalances a channel entirely. We've also showed how one can
</I>&gt;<i> &gt; utilize
</I>&gt;<i> &gt; the current onion packet format to deliver additional data from a
</I>&gt;<i> &gt; sender to
</I>&gt;<i> &gt; receiver, that's still e2e authenticated.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; -- Conner &amp;&amp; Laolu
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; _______________________________________________
</I>&gt;<i> &gt; Lightning-dev mailing list
</I>&gt;<i> &gt; <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">Lightning-dev at lists.linuxfoundation.org</A>
</I>&gt;<i> &gt; <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> Lightning-dev mailing list
</I>&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">Lightning-dev at lists.linuxfoundation.org</A>
</I>&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev</A>
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180211/27d3755e/attachment-0001.html">http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180211/27d3755e/attachment-0001.html</A>&gt;
</PRE>





<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001015.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
	<LI>Next message: <A HREF="001019.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1017">[ date ]</a>
              <a href="thread.html#1017">[ thread ]</a>
              <a href="subject.html#1017">[ subject ]</a>
              <a href="author.html#1017">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">More information about the Lightning-dev
mailing list</a><br>
</body></html>
