<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
   </TITLE>
   <LINK REL="Index" HREF="https://lists.linuxfoundation.org/pipermail/lightning-dev/2018-February/index.html" >
   <LINK REL="made" HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20AMP%3A%20Atomic%20Multi-Path%20Payments%20over%20Lightning&In-Reply-To=%3CxGkm-WdULsVZa_MpFrkgyauZu0QVbPzCVPFPlC62c3g_BRxkxEn3DFyJCqiqik8L1_dMse88Kfyz2JGEc8obzKordLMOjBD3Vmdz0LrzTIw%3D%40protonmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001017.html">
   <LINK REL="Next"  HREF="001021.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning</H1>
    <B>ZmnSCPxj</B> 
    <A HREF="mailto:lightning-dev%40lists.linuxfoundation.org?Subject=Re:%20Re%3A%20%5BLightning-dev%5D%20AMP%3A%20Atomic%20Multi-Path%20Payments%20over%20Lightning&In-Reply-To=%3CxGkm-WdULsVZa_MpFrkgyauZu0QVbPzCVPFPlC62c3g_BRxkxEn3DFyJCqiqik8L1_dMse88Kfyz2JGEc8obzKordLMOjBD3Vmdz0LrzTIw%3D%40protonmail.com%3E"
       TITLE="[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning">ZmnSCPxj at protonmail.com
       </A><BR>
    <I>Mon Feb 12 03:03:37 UTC 2018</I>
    <P><UL>
        <LI>Previous message: <A HREF="001017.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
        <LI>Next message: <A HREF="001021.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1019">[ date ]</a>
              <a href="thread.html#1019">[ thread ]</a>
              <a href="subject.html#1019">[ subject ]</a>
              <a href="author.html#1019">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Good morning Cezary,

&gt;<i> That would be great improvement, if AMP could work this way:
</I>&gt;<i>
</I>&gt;<i> 1. I would like to send 0.1 BTC, so I split this to 5 payment 0.02 BTC each + one extra 0.02 BTC payment.
</I>&gt;<i> 2. When recipient received 6 htlcs, he is able to spend only 5 of them.
</I>&gt;<i> If recipient receives, only 5 of them, it is still fine, and payment is success.
</I>&gt;<i>
</I>&gt;<i> In such scenario, single route/payment would fail, and payment as whole would still be success. Do you think that would be possible? It could greatly increase reliability of LN payments.
</I>
I will leave it to better mathematicians to answer your direct question, but, my intuition suggests it is not possible as stated.

However, let me propose an alternative AMP method instead.

------

Roughly, we want to proceed this way.

1.  When paying:
1.1.  Try to pay.
1.2.  If it fails, split it into two smaller payments and recurse into 1.

Now we should ensure that the receiver can only receive if it has received all payments, and once it has received all payments, it can claim all payments.

So let me first introduce the below dual:

* A pseudorandom number generator can be represented by its algorithm and the seed.  Alternatively, it can be represented by a stream of numbers.

Now, a  stream of numbers has no end, but it does have a start (i.e. the first random number generated by the PRNG from the seed).  It is possible to &quot;split&quot; a stream into two streams, by taking the 0th, 2nd, 4th... numbers in one stream, and taking the 1st, 3rd, 5th... numbers in the other stream.

Each such &quot;split&quot; stream can itself be further split into two streams.  Split streams can be re-&quot;merged&quot; by interleaving their members to yield the original pre-split stream.

Now, we also want to be able to split a random seed into two seeds.  This splitting need not correspond to the stream-split (i.e. the split seeds will NOT generate the split streams); we only need to split seeds to prevent the receiver from claiming partial amounts.  This can be done by using another random source to generate a new &quot;seed&quot;, and XOR it with the real seed.  The split &quot;halves&quot; are then the random number, and seed XOR the random number; the result is two apparently random numbers which, when XORed together, generate the original seed.

Let us now sketch our algorithm:

1.  def pay(seed, stream, dest, amount):
1.1.  try { r = route(dest, amount, randomstuff); offer_htlc(H(stream[0]), r, seed, stream);
1.2.  } catch(PaymentFailure) { sd1, sd2 = split_seed(seed); sr1, sr2 = split_stream(stream); pay(sd1, sr1, dest, amount / 2); pay(sd2, sr2, dest, amount / 2); }

Now notice that the hash we use is H(stream[0]).  That is, the first item in the stream of random numbers.  Thus our streams do not actually need to give anything more than the first number in a stream.  We can represent a &quot;split&quot; stream simply by the index into the original stream.  For example, if we have:

    s = original stream
    sl, sr = split_stream(s)
    sll, slr = split_stream(sl)

Then s[0] and sl[0] and sll[0] are simply index 0 into the original stream, sr[0] is index 1, and slr[0] is index 2.  We can thus represent streams and their splits by the tuple (seed, index, depth), where depth indicates how many splits the stream has been through.  So, for the below:

    s = (seed, 0, 0)
    sl, sr = split_stream(s) = (seed, 0, 1), (seed, 1, 1)
    sll, slr = split_stream(sl) = (seed, 0, 2), (seed, 2, 2)
    split_stream( (seed, index, depth) ) = (seed, index, depth + 1), (seed, index + 2**depth, depth + 1)

Then, for any stream s whose RNG algorithm is PRNG:

   s[0] = (seed, index, _)[0] = PRNG(seed)[index]

Let us now consider how our payment might proceed.

1.  First, we generate a random seed, and call pay(seed, (seed, 0, 0), dest, amount)
2.  Let us suppose that payment fails for the entire amount.  Split the amount into two:
2.1.  In one branch we have pay(X, (seed, 0, 1), dest, amount / 2).  X is a new random number.
2.2.  In other branch we have pay(seed ^ X, (seed, 1, 1), dest, amount / 2).  X is the same number as branch 2.1.
2.2.1.  Suppose this payment fails.  Split it again intow two payments:
2.2.1.1  In one sub-branch we have pay(Y, (seed, 1, 2), dest, amount / 4).
2.2.1.2.  In other sub-branch we have pay(seed ^ X ^ Y, (seed, 3, 2), dest, amount / 4).

The receiver receives the branches 2.1, 2.2.1.1, and 2.2.1.2., which provide the seeds:

2.1. =&gt; X
2.2.1.1 =&gt; Y
2.2.1.2. =&gt; seed ^X ^ Y

Xoring all of the above provides X ^ Y ^ seed ^ X ^ Y = seed.

The receiver can claim branch 2.1. by using PRNG(seed)[0], can claim branch 2.2.1.1 using PRNG(seed)[1], and branch 2.2.1.2 using PRNG(seed)[3].

Thus the sender needs only to send the split seed (say 32 bytes) and the index (say 1 byte for up to 8-level splitting into up to 256 payments).  The receiver gathers each split seed, XOR them all together to get the original PRNG seed, and runs the PRNG the appropriate number of times to get the preimages of each payment.

(pragmatically we also need some kind of payment ID to differentiate different logical payments from the same sender, and to differentiate it from non-AMP)

The receiver cannot claim partial payments as it cannot determine the original seed until all branches of the payment reach it.  Once it has received all branches of the payment, however, it can determine the seed and the preimage of each payment; once it does so it has incentive to get all branches, yielding atomicity.

Regards,
ZmnSCPxj

&gt;<i> 2018-02-09 11:15 GMT+01:00 CJP &lt;<A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">cjp at ultimatestunts.nl</A>&gt;:
</I>&gt;<i>
</I>&gt;&gt;<i> Can you give a use case for this?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Usually, especially in the common case that a payment is done in
</I>&gt;&gt;<i> exchange for some non-cryptographic asset (e.g. physical goods), there
</I>&gt;&gt;<i> already is some kind of trust between payer and payee. So, if a payment
</I>&gt;&gt;<i> is split non-atomically into smaller transactions, and only a part
</I>&gt;&gt;<i> succeeds, presumably they can cooperatively figure out some way to
</I>&gt;&gt;<i> settle the situation.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I spoke to people of the &quot;interledger&quot; project, and what they are
</I>&gt;&gt;<i> planning to do is to non-atomically split *every* transaction into lots
</I>&gt;&gt;<i> of micro-payments. In fact, they consider it unnecessary to enforce
</I>&gt;&gt;<i> HTLCs with scripts, because their amounts are so small(*). If one
</I>&gt;&gt;<i> micro-payment fails, that just makes them learn that a certain channel
</I>&gt;&gt;<i> is unreliable, and they'll send further payments (and even the remaining
</I>&gt;&gt;<i> part of the same payment) through a different route.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> CJP
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> (*) not worth the extra on-blockchain fee due to the increased tx size.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Olaoluwa Osuntokun schreef op di 06-02-2018 om 05:26 [+0000]:
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Hi Y'all,
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> A common question I've seen concerning Lightning is: &quot;I have five $2
</I>&gt;&gt;&gt;<i> channels, is it possible for me to *atomically* send $6 to fulfill a
</I>&gt;&gt;&gt;<i> payment?&quot;. The answer to this question is &quot;yes&quot;, provided that the
</I>&gt;&gt;&gt;<i> receiver
</I>&gt;&gt;&gt;<i> waits to pull all HTLC's until the sum matches their invoice.
</I>&gt;&gt;&gt;<i> Typically, one
</I>&gt;&gt;&gt;<i> assumes that the receiver will supply a payment hash, and the sender
</I>&gt;&gt;&gt;<i> will
</I>&gt;&gt;&gt;<i> re-use the payment hash for all streams. This has the downside of
</I>&gt;&gt;&gt;<i> payment
</I>&gt;&gt;&gt;<i> hash re-use across *multiple* payments (which can already easily be
</I>&gt;&gt;&gt;<i> correlated), and also has a failure mode where if the sender fails to
</I>&gt;&gt;&gt;<i> actually satisfy all the payment flows, then the receiver can still
</I>&gt;&gt;&gt;<i> just
</I>&gt;&gt;&gt;<i> pull the monies (and possibly not disperse a service, or w/e).
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Conner Fromknecht and I have come up with a way to achieve this over
</I>&gt;&gt;&gt;<i> Lightning while (1) not re-using any payment hashes across all payment
</I>&gt;&gt;&gt;<i> flows, and (2) adding a *strong* guarantee that the receiver won't be
</I>&gt;&gt;&gt;<i> paid
</I>&gt;&gt;&gt;<i> until *all* partial payment flows are extended. We call this scheme
</I>&gt;&gt;&gt;<i> AMP
</I>&gt;&gt;&gt;<i> (Atomic Multi-path Payments). It can be experimented with on Lightning
</I>&gt;&gt;&gt;<i> *today* with the addition of a new feature bit to gate this new
</I>&gt;&gt;&gt;<i> feature. The beauty of the scheme is that it requires no fundamental
</I>&gt;&gt;&gt;<i> changes
</I>&gt;&gt;&gt;<i> to the protocol as is now, as the negotiation is strictly *end-to-end*
</I>&gt;&gt;&gt;<i> between sender and receiver.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> TL;DR: we repurpose some unused space in the onion per-hop payload of
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> onion blob to signal our protocol (and deliver some protocol-specific
</I>&gt;&gt;&gt;<i> data),
</I>&gt;&gt;&gt;<i> then use additive secret sharing to ensure that the receiver can't
</I>&gt;&gt;&gt;<i> pull the
</I>&gt;&gt;&gt;<i> payment until they have enough shares to reconstruct the original
</I>&gt;&gt;&gt;<i> pre-image.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Protocol Goals
</I>&gt;&gt;&gt;<i> ==============
</I>&gt;&gt;&gt;<i> 1. Atomicity: The logical transaction should either succeed or fail in
</I>&gt;&gt;&gt;<i> entirety. Naturally, this implies that the receiver should not be
</I>&gt;&gt;&gt;<i> unable to
</I>&gt;&gt;&gt;<i> settle *any* of the partial payments, until all of them have arrived.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> 2. Avoid Payment Hash Reuse: The payment preimages validated by the
</I>&gt;&gt;&gt;<i> consensus layer should be distinct for each partial payment.
</I>&gt;&gt;&gt;<i> Primarily,
</I>&gt;&gt;&gt;<i> this helps avoid correlation of the partial payments, and ensures that
</I>&gt;&gt;&gt;<i> malicious intermediaries straddling partial payments cannot steal
</I>&gt;&gt;&gt;<i> funds.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> 3. Order Invariance: The protocol should be forgiving to the order in
</I>&gt;&gt;&gt;<i> which
</I>&gt;&gt;&gt;<i> partial payments arrive at the destination, adding robustness in the
</I>&gt;&gt;&gt;<i> face of
</I>&gt;&gt;&gt;<i> delays or routing failures.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> 4. Non-interactive Setup: It should be possible for the sender to
</I>&gt;&gt;&gt;<i> perform an
</I>&gt;&gt;&gt;<i> AMP without directly coordinating with the receiving node.
</I>&gt;&gt;&gt;<i> Predominantly,
</I>&gt;&gt;&gt;<i> this means that the *sender* is able to determine the number of
</I>&gt;&gt;&gt;<i> partial
</I>&gt;&gt;&gt;<i> payments to use for a particular AMP, which makes sense since they
</I>&gt;&gt;&gt;<i> will be
</I>&gt;&gt;&gt;<i> the one fronting the fees for the cost of this parameter. Plus, we can
</I>&gt;&gt;&gt;<i> always turn a non-interactive protocol into an interactive one for the
</I>&gt;&gt;&gt;<i> purposes of invoicing.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Protocol Benefits
</I>
&gt;&gt;&gt;<i> =================
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Sending pay payments predominantly over an AMP-like protocol has
</I>&gt;&gt;&gt;<i> several
</I>&gt;&gt;&gt;<i> clear benefits:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - Eliminates the constraint that a single path from sender to
</I>&gt;&gt;&gt;<i> receiver
</I>&gt;&gt;&gt;<i>     with sufficient directional capacity. This reduces the pressure to
</I>&gt;&gt;&gt;<i> have
</I>&gt;&gt;&gt;<i>     larger channels in order to support larger payment flows. As a
</I>&gt;&gt;&gt;<i> result,
</I>&gt;&gt;&gt;<i>     the payment graph be very diffused, without sacrificing payment
</I>&gt;&gt;&gt;<i>     utility
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - Reduces strain from larger payments on individual paths, and
</I>&gt;&gt;&gt;<i> allows the
</I>&gt;&gt;&gt;<i>     liquidity imbalances to be more diffuse. We expect this to have a
</I>&gt;&gt;&gt;<i>     non-negligible impact on channel longevity. This is due to the
</I>&gt;&gt;&gt;<i> fact that
</I>&gt;&gt;&gt;<i>     with usage of AMP, payment flows are typically *smaller* meaning
</I>&gt;&gt;&gt;<i> that
</I>&gt;&gt;&gt;<i>     each payment will unbalance a channel to a lesser degree that
</I>&gt;&gt;&gt;<i>     with one giant flow.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - Potential fee savings for larger payments, contingent on there
</I>&gt;&gt;&gt;<i> being a
</I>&gt;&gt;&gt;<i>     super-linear component to routed fees. It's possible that with
</I>&gt;&gt;&gt;<i>     modifications to the fee schedule, it's actually *cheaper* to send
</I>&gt;&gt;&gt;<i>     payments over multiple flows rather than one giant flow.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - Allows for logical payments larger than the current maximum value
</I>&gt;&gt;&gt;<i> of an
</I>&gt;&gt;&gt;<i>     individual payment. Atm we have a (temporarily) limit on the max
</I>&gt;&gt;&gt;<i> payment
</I>&gt;&gt;&gt;<i>     size. With AMP, this can be side stepped as each flow can be up
</I>&gt;&gt;&gt;<i> the max
</I>&gt;&gt;&gt;<i>     size, with the sum of all flows exceeding the max.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - Given sufficient path diversity, AMPs may improve the privacy of
</I>&gt;&gt;&gt;<i> LN
</I>&gt;&gt;&gt;<i>     Intermediaries are now unaware to how much of the total payment
</I>&gt;&gt;&gt;<i> they are
</I>&gt;&gt;&gt;<i>     forwarding, or even if they are forwarding a partial payment at
</I>&gt;&gt;&gt;<i> all.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - Using smaller payments increases the set of possible paths a
</I>&gt;&gt;&gt;<i> partial
</I>&gt;&gt;&gt;<i>     payment could have taken, which reduces the effectiveness of
</I>&gt;&gt;&gt;<i> static
</I>&gt;&gt;&gt;<i>     analysis techniques involving channel capacities and the plaintext
</I>&gt;&gt;&gt;<i>     values being forwarded.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Protocol Overview
</I>&gt;&gt;&gt;<i> ==================
</I>&gt;&gt;&gt;<i> This design can be seen as a generalization of the single,
</I>&gt;&gt;&gt;<i> non-interactive
</I>&gt;&gt;&gt;<i> payment scheme, that uses decoding of extra onion blobs (EOBs?) to
</I>&gt;&gt;&gt;<i> encode
</I>&gt;&gt;&gt;<i> extra data for the receiver. In that design, the extra data includes a
</I>&gt;&gt;&gt;<i> payment preimage that the receiver can use to settle back the payment.
</I>&gt;&gt;&gt;<i> EOBs
</I>&gt;&gt;&gt;<i> and some method of parsing them are really the only requirement for
</I>&gt;&gt;&gt;<i> this
</I>&gt;&gt;&gt;<i> protocol to work. Thus, only the sender and receiver need to implement
</I>&gt;&gt;&gt;<i> this
</I>&gt;&gt;&gt;<i> feature in order for it to function, which can be announced using a
</I>&gt;&gt;&gt;<i> feature
</I>&gt;&gt;&gt;<i> bit.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> First, let's review the current format of the per-hop payload for each
</I>&gt;&gt;&gt;<i> node
</I>&gt;&gt;&gt;<i> described in BOLT-0004.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
</I>&gt;&gt;&gt;<i> &#9474;Realm (1 byte) &#9474;Next Addr (8 bytes)&#9474;Amount (8 bytes)&#9474;Outgoing CLTV (4
</I>&gt;&gt;&gt;<i> bytes)&#9474;Unused (12 bytes)&#9474; HMAC (32 bytes) &#9474;
</I>&gt;&gt;&gt;<i> &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
</I>&gt;&gt;&gt;<i> &#9632;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9632;
</I>&gt;&gt;&gt;<i>                                               &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
</I>&gt;&gt;&gt;<i>                                               &#9474;65 Bytes Per Hop &#9474;
</I>&gt;&gt;&gt;<i>                                               &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Currently, *each* node gets a 65-byte payload. We use this payload to
</I>&gt;&gt;&gt;<i> give
</I>&gt;&gt;&gt;<i> each node instructions on *how* to forward a payment. We tell each
</I>&gt;&gt;&gt;<i> node: the
</I>&gt;&gt;&gt;<i> realm (or chain to forward on), then next node to forward to, the
</I>&gt;&gt;&gt;<i> amount to
</I>&gt;&gt;&gt;<i> forward (this is where fees are extracted by forwarding out less than
</I>&gt;&gt;&gt;<i> in),
</I>&gt;&gt;&gt;<i> the outgoing CLTV (allows verification that the prior node didn't
</I>&gt;&gt;&gt;<i> modify any
</I>&gt;&gt;&gt;<i> values), and finally an HMAC over the entire thing.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Two important points:
</I>&gt;&gt;&gt;<i>   1. We have 12 bytes for each hop that are currently unpurposed and
</I>&gt;&gt;&gt;<i> can be
</I>&gt;&gt;&gt;<i>   used by application protocols to signal new interpretation of bytes
</I>&gt;&gt;&gt;<i> and
</I>&gt;&gt;&gt;<i>   also deliver additional encrypted+authenticated data to *each* hop.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   2. The protocol currently has a hard limit of 20-hops. With this
</I>&gt;&gt;&gt;<i> feature
</I>&gt;&gt;&gt;<i>   we ensure that the packet stays fixed sized during processing in
</I>&gt;&gt;&gt;<i> order to
</I>&gt;&gt;&gt;<i>   avoid leaking positional information. Typically most payments won't
</I>&gt;&gt;&gt;<i> use
</I>&gt;&gt;&gt;<i>   all 20 hops, as a result, we can use the remaining hops to stuff in
</I>&gt;&gt;&gt;<i> *even
</I>&gt;&gt;&gt;<i>   more* data.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Protocol Description
</I>&gt;&gt;&gt;<i> ====================
</I>&gt;&gt;&gt;<i> The solution we propose is Atomic Multi-path Payments (AMPs). At a
</I>&gt;&gt;&gt;<i> high
</I>&gt;&gt;&gt;<i> level, this leverages EOBs to deliver additive shares of a base
</I>&gt;&gt;&gt;<i> preimage,
</I>&gt;&gt;&gt;<i> from which the payment preimages of partial payments can be derived.
</I>&gt;&gt;&gt;<i> The
</I>&gt;&gt;&gt;<i> receiver can only construct this value after having received all of
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> partial payments, satisfying the atomicity constraint.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The basic protocol:
</I>

&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Primitives
</I>&gt;&gt;&gt;<i> ==========
</I>&gt;&gt;&gt;<i> Let H be a CRH function.
</I>&gt;&gt;&gt;<i> Let || denote concatenation.
</I>&gt;&gt;&gt;<i> Let ^ denote xor.
</I>

&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Sender Requirements
</I>&gt;&gt;&gt;<i> ===================
</I>&gt;&gt;&gt;<i> The parameters to the sending procedure are a random identifier ID,
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> number of partial payments n, and the total payment value V. Assume
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> sender has some way of dividing V such that V = v_1 + &#8230; + v_n.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> To begin, the sender builds the base preimage BP, from which n partial
</I>&gt;&gt;&gt;<i> preimages will be derived. Next, the sender samples n additive shares
</I>&gt;&gt;&gt;<i> s_1,
</I>&gt;&gt;&gt;<i> &#8230;, s_n, and takes the sum to compute BP = s_1 ^ &#8230; ^ s_n.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> With the base preimage created, the sender now moves on to
</I>&gt;&gt;&gt;<i> constructing the
</I>&gt;&gt;&gt;<i> n partial payments. For each i in [1,n], the sender deterministically
</I>&gt;&gt;&gt;<i> computes the partial preimage r_i = H(BP ||  i), by concatenating the
</I>&gt;&gt;&gt;<i> sequence number i to the base preimage and hashing the result.
</I>&gt;&gt;&gt;<i> Afterwards,
</I>&gt;&gt;&gt;<i> it applies H to determine the payment hash to use in the i&#8217;th partial
</I>&gt;&gt;&gt;<i> payment as h_i = H(r_i). Note that that with this preimage derivation
</I>&gt;&gt;&gt;<i> scheme, once the payments are pulled each pre-image is distinct and
</I>&gt;&gt;&gt;<i> indistinguishable from any other.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> With all of the pieces in place, the sender initiates the i&#8217;th payment
</I>&gt;&gt;&gt;<i> by
</I>&gt;&gt;&gt;<i> constructing a route to the destination with value v_i and payment
</I>&gt;&gt;&gt;<i> hash h_i.
</I>&gt;&gt;&gt;<i> The tuple (ID, n, s_i) is included in the EOB to be opened by the
</I>&gt;&gt;&gt;<i> receiver.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> In order to include the three tuple within the per-hop payload for the
</I>&gt;&gt;&gt;<i> final
</I>&gt;&gt;&gt;<i> destination, we repurpose the _first_ byte of the un-used padding
</I>&gt;&gt;&gt;<i> bytes in
</I>&gt;&gt;&gt;<i> the payload to signal version 0x01 of the AMP protocol (note this is a
</I>&gt;&gt;&gt;<i> PoC
</I>&gt;&gt;&gt;<i> outline, we would need to standardize signalling of these 12 bytes to
</I>&gt;&gt;&gt;<i> support other protocols). Typically this byte isn't set, so the
</I>&gt;&gt;&gt;<i> existence of
</I>&gt;&gt;&gt;<i> this means that we're (1) using AMP, and (2) the receiver should
</I>&gt;&gt;&gt;<i> consume the
</I>&gt;&gt;&gt;<i> _next_ hop as well. So if the payment length is actually 5, the sender
</I>&gt;&gt;&gt;<i> tacks
</I>&gt;&gt;&gt;<i> on an additional dummy 6th hop, encrypted with the _same_ shared
</I>&gt;&gt;&gt;<i> secret for
</I>&gt;&gt;&gt;<i> that hop to deliver the e2e encrypted data.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Note, the sender can retry partial payments just as they would normal
</I>&gt;&gt;&gt;<i> payments, since they are order invariant, and would be
</I>&gt;&gt;&gt;<i> indistinguishable
</I>&gt;&gt;&gt;<i> from regular payments to intermediaries in the network.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Receiver
</I>Requirements
&gt;&gt;&gt;<i> =====================
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Upon the arrival of each partial payment, the receiver will
</I>&gt;&gt;&gt;<i> iteratively
</I>&gt;&gt;&gt;<i> reconstruct BP, and do some bookkeeping to figure out when to settle
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> partial payments. During this reconstruction process, the receiver
</I>&gt;&gt;&gt;<i> does not
</I>&gt;&gt;&gt;<i> need to be aware of the order in which the payments were sent, and in
</I>&gt;&gt;&gt;<i> fact
</I>&gt;&gt;&gt;<i> nothing about the incoming partial payments reveals this information
</I>&gt;&gt;&gt;<i> to the
</I>&gt;&gt;&gt;<i> receiver, though this can be learned after reconstructing BP.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Each EOB is decoded to retrieve (ID, n, s_i), where i is the unique
</I>&gt;&gt;&gt;<i> but
</I>&gt;&gt;&gt;<i> unknown index of the incoming partial payment. The receiver has access
</I>&gt;&gt;&gt;<i> to
</I>&gt;&gt;&gt;<i> persistent key-value store DB that maps ID to (n, c*, BP*), where c*
</I>&gt;&gt;&gt;<i> represents the number of partial payments received, BP* is the sum of
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> received additive shares, and the superscript * denotes that the value
</I>&gt;&gt;&gt;<i> is
</I>&gt;&gt;&gt;<i> being updated iteratively. c* and BP* both have initial values of 0.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> In the basic protocol, the receiver cache&#8217;s the first n it sees, and
</I>&gt;&gt;&gt;<i> verifies that all incoming partial payments have the same n. The
</I>&gt;&gt;&gt;<i> receiver
</I>&gt;&gt;&gt;<i> should reject all partial payments if any EOB deviates.  Next, the we
</I>&gt;&gt;&gt;<i> update
</I>&gt;&gt;&gt;<i> our persistent store with DB[ID] = (n, c* + 1, BP* ^ s_i), advancing
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> reconstruction by one step.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> If c* + 1 &lt; n, there are still more packets in flight, so we sit
</I>&gt;&gt;&gt;<i> tight.
</I>&gt;&gt;&gt;<i> Otherwise, the receiver assumes all partial payments have arrived, and
</I>&gt;&gt;&gt;<i> can
</I>&gt;&gt;&gt;<i> being settling them back. Using the base preimage BP = BP* ^ s_i from
</I>&gt;&gt;&gt;<i> our
</I>&gt;&gt;&gt;<i> final iteration, the receiver can re-derive all n partial preimages
</I>&gt;&gt;&gt;<i> and
</I>&gt;&gt;&gt;<i> payment hashes, using r_i = H(BP || i) and h_i = H(r_i) simply through
</I>&gt;&gt;&gt;<i> knowledge of n and BP.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Finally, the receiver settles back any outstanding payments that
</I>&gt;&gt;&gt;<i> include
</I>&gt;&gt;&gt;<i> payment hash h_i using the partial preimage r_i. Each r_i will appear
</I>&gt;&gt;&gt;<i> random
</I>&gt;&gt;&gt;<i> due to the nature of H, as will it&#8217;s corresponding h_i. Thus, each
</I>&gt;&gt;&gt;<i> partial
</I>&gt;&gt;&gt;<i> payment should appear uncorrelated, and does not reveal that it is
</I>&gt;&gt;&gt;<i> part of
</I>&gt;&gt;&gt;<i> an AMP nor the number of partial payments used.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Non-interactive to Interactive AMPs
</I>&gt;&gt;&gt;<i> ===================================
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Sender simply receives an ID and amount from the receiver in an
</I>&gt;&gt;&gt;<i> invoice
</I>&gt;&gt;&gt;<i> before initiating the protocol. The receiver should only consider the
</I>&gt;&gt;&gt;<i> invoice settled if the total amount received in partial payments
</I>&gt;&gt;&gt;<i> containing
</I>&gt;&gt;&gt;<i> ID matches or exceeds the amount specified in the invoice. With this
</I>&gt;&gt;&gt;<i> variant, the receiver is able to map all partial payments to a
</I>&gt;&gt;&gt;<i> pre-generated
</I>&gt;&gt;&gt;<i> invoice statement.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Additive Shares vs Threshold-Shares
</I>&gt;&gt;&gt;<i> ===================================
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The biggest reason to use additive shares seems to be atomicity.
</I>&gt;&gt;&gt;<i> Threshold
</I>&gt;&gt;&gt;<i> shares open the door to some partial payments being settled, even if
</I>&gt;&gt;&gt;<i> others
</I>&gt;&gt;&gt;<i> are left in flight. Haven&#8217;t yet come up with a good reason for using
</I>&gt;&gt;&gt;<i> threshold schemes, but there seem to be plenty against it.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Reconstruction of additive shares can be done iteratively, and is win
</I>&gt;&gt;&gt;<i> for
</I>&gt;&gt;&gt;<i> the storage and computation requirements on the receiving end. If the
</I>&gt;&gt;&gt;<i> sender
</I>&gt;&gt;&gt;<i> decides to use fewer than n partial payments, the remaining shares
</I>&gt;&gt;&gt;<i> could be
</I>&gt;&gt;&gt;<i> included in the EOB of the final partial payment to allow the sender
</I>&gt;&gt;&gt;<i> to
</I>&gt;&gt;&gt;<i> reconstruct sooner. Sender could also optimistically do partial
</I>&gt;&gt;&gt;<i> reconstruction on this last aggregate value.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Adaptive AMPs
</I>&gt;&gt;&gt;<i> =============
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The sender may not always be aware of how many partial payments they
</I>&gt;&gt;&gt;<i> wish to
</I>&gt;&gt;&gt;<i> send at the time of the first partial payment, at which point the
</I>&gt;&gt;&gt;<i> simplified
</I>&gt;&gt;&gt;<i> protocol would require n to be chosen. To accommodate, the above
</I>&gt;&gt;&gt;<i> scheme can
</I>&gt;&gt;&gt;<i> be adapted to handle a dynamically chosen n by iteratively
</I>&gt;&gt;&gt;<i> constructing the
</I>&gt;&gt;&gt;<i> shared secrets as follows.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Starting with a base preimage BP, the key trick is that the sender
</I>&gt;&gt;&gt;<i> remember
</I>&gt;&gt;&gt;<i> the difference between the base preimage and the sum of all partial
</I>&gt;&gt;&gt;<i> preimages used so far. The relation is described using the following
</I>&gt;&gt;&gt;<i> equations:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>     X_0 = 0
</I>
&gt;&gt;&gt;<i>     X_i = X_{i-1} ^ s_i
</I>
&gt;&gt;&gt;<i>     X_n = BP ^ X_{n-1}
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> where if n=1, X_1 = BP, implying that this is in fact a generalization
</I>&gt;&gt;&gt;<i> of
</I>&gt;&gt;&gt;<i> the single, non-interactive payment scheme mentioned above. For
</I>&gt;&gt;&gt;<i> i=1, ...,
</I>&gt;&gt;&gt;<i> n-1, the sender sends s_i in the EOB, and  X_n for the n-th share.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Iteratively reconstructing s_1 ^ &#8230;. ^ s_{n-1} ^ X_n = BP, allows the
</I>&gt;&gt;&gt;<i> receiver to compute all relevant r_i = H(BP || i) and h_i = H(r_i).
</I>&gt;&gt;&gt;<i> Lastly,
</I>&gt;&gt;&gt;<i> the final number of partial payments n could be signaled in the final
</I>&gt;&gt;&gt;<i> EOB,
</I>&gt;&gt;&gt;<i> which would also serve as a sentinel value for signaling completion.
</I>&gt;&gt;&gt;<i> In
</I>&gt;&gt;&gt;<i> response to DOS vectors stemming from unknown values of n,
</I>&gt;&gt;&gt;<i> implementations
</I>&gt;&gt;&gt;<i> could consider advertising a maximum value for n, or adopting some
</I>&gt;&gt;&gt;<i> sort of
</I>&gt;&gt;&gt;<i> framing pattern for conveying that more partial payments are on the
</I>&gt;&gt;&gt;<i> way.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> We can further modify our usage of the per-hop payloads to send
</I>&gt;&gt;&gt;<i> (H(BP), s_i) to
</I>&gt;&gt;&gt;<i> consume most of the EOB sent from sender to receiver. In this
</I>&gt;&gt;&gt;<i> scenario, we'd
</I>&gt;&gt;&gt;<i> repurpose the 11-bytes *after* our signalling byte in the unused byte
</I>&gt;&gt;&gt;<i> section
</I>&gt;&gt;&gt;<i> to store the payment ID (which should be unique for each payment). In
</I>&gt;&gt;&gt;<i> the case
</I>&gt;&gt;&gt;<i> of a non-interactive payment, this will be unused. While for
</I>&gt;&gt;&gt;<i> interactive
</I>&gt;&gt;&gt;<i> payments, this will be the ID within the invoice. To deliver this
</I>&gt;&gt;&gt;<i> slimmer
</I>&gt;&gt;&gt;<i> 2-tuple, we'll use 32-bytes for the hash of the BP, and 32-bytes for
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> partial pre-image share, leaving an un-used byte in the payload.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Cross-Chain AMPs
</I>&gt;&gt;&gt;<i> ================
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> AMPs can be used to pay a receiver in multiple currencies
</I>&gt;&gt;&gt;<i> atomically...which
</I>&gt;&gt;&gt;<i> is pretty cool :D
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Open Research Questions
</I>&gt;&gt;&gt;<i> =======================
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The above is a protocol sketch to achieve atomic multi-path payments
</I>&gt;&gt;&gt;<i> over
</I>&gt;&gt;&gt;<i> Lightning. The details concerning onion blob usage serves as a
</I>&gt;&gt;&gt;<i> template that
</I>&gt;&gt;&gt;<i> future protocols can draw upon in order to deliver additional data to
</I>&gt;&gt;&gt;<i> *any*
</I>&gt;&gt;&gt;<i> hop in the route. However, there are still a few open questions before
</I>&gt;&gt;&gt;<i> something like this can be feasibly deployed.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> 1. How does the sender decide how many chunked payments to send, and
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> size of each payment?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - Upon a closer examination, this seems to overlap with the task of
</I>&gt;&gt;&gt;<i>     congestion control within TCP. The sender may be able to utilize
</I>&gt;&gt;&gt;<i>     inspired heuristics to gauge: (1) how large the initial payment
</I>&gt;&gt;&gt;<i> should be
</I>&gt;&gt;&gt;<i>     and (2) how many subsequent payments may be required. Note that if
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i>     first payment succeeds, then the exchange is over in a signal
</I>&gt;&gt;&gt;<i> round.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> 2. How can AMP and HORNET be composed?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>   - If we eventually integrate HORNET, then a distinct communications
</I>&gt;&gt;&gt;<i>     sessions can be established to allow the sender+receiver to
</I>&gt;&gt;&gt;<i> exchange
</I>&gt;&gt;&gt;<i>     up-to-date partial payment information. This may allow the sender
</I>&gt;&gt;&gt;<i> to more
</I>&gt;&gt;&gt;<i>     accurately size each partial payment.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> 3. Can the sender's initial strategy be governed by an instance of the
</I>&gt;&gt;&gt;<i> Push-relabel max flow algo?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> 4. How does this mesh with the current max HTLC limit on a commitment?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>    - ATM, we have a max limit on the number of active HTLC's on a
</I>&gt;&gt;&gt;<i> particular
</I>&gt;&gt;&gt;<i>      commitment transaction. We do this, as otherwise it's possible
</I>&gt;&gt;&gt;<i> that the
</I>&gt;&gt;&gt;<i>      transaction is too large, and exceeds standardness w.r.t
</I>&gt;&gt;&gt;<i> transaction
</I>&gt;&gt;&gt;<i>      size. In a world where most payments use an AMP-like protocol,
</I>&gt;&gt;&gt;<i> then
</I>&gt;&gt;&gt;<i>      overall ant any given instance there will be several pending
</I>&gt;&gt;&gt;<i> HTLC's on
</I>&gt;&gt;&gt;<i>      commitments network wise.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>      This may incentivize nodes to open more channels in order to
</I>&gt;&gt;&gt;<i> support
</I>&gt;&gt;&gt;<i>      the increased commitment space utilization.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Conclusion
</I>&gt;&gt;&gt;<i> ==========
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> We've presented a design outline of how to integrate atomic multi-path
</I>&gt;&gt;&gt;<i> payments (AMP) into Lightning. The existence of such a construct
</I>&gt;&gt;&gt;<i> allows a
</I>&gt;&gt;&gt;<i> sender to atomically split a payment flow amongst several individual
</I>&gt;&gt;&gt;<i> payment
</I>&gt;&gt;&gt;<i> flows. As a result, larger channels aren't as important as it's
</I>&gt;&gt;&gt;<i> possible to
</I>&gt;&gt;&gt;<i> utilize one total outbound payment bandwidth to send several channels.
</I>&gt;&gt;&gt;<i> Additionally, in order to support the increased load, internal routing
</I>&gt;&gt;&gt;<i> nodes
</I>&gt;&gt;&gt;<i> are incensed have more active channels. The existence of AMP-like
</I>&gt;&gt;&gt;<i> payments
</I>&gt;&gt;&gt;<i> may also increase the longevity of channels as there'll be smaller,
</I>&gt;&gt;&gt;<i> more
</I>&gt;&gt;&gt;<i> numerous payment flows, making it unlikely that a single payment comes
</I>&gt;&gt;&gt;<i> across unbalances a channel entirely. We've also showed how one can
</I>&gt;&gt;&gt;<i> utilize
</I>&gt;&gt;&gt;<i> the current onion packet format to deliver additional data from a
</I>&gt;&gt;&gt;<i> sender to
</I>&gt;&gt;&gt;<i> receiver, that's still e2e authenticated.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> -- Conner &amp;&amp; Laolu
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;&gt;<i> Lightning-dev mailing list
</I>&gt;&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">Lightning-dev at lists.linuxfoundation.org</A>
</I>&gt;&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev</A>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;<i> Lightning-dev mailing list
</I>&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">Lightning-dev at lists.linuxfoundation.org</A>
</I>&gt;&gt;<i> <A HREF="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev</A>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180211/5074c519/attachment-0001.html">http://lists.linuxfoundation.org/pipermail/lightning-dev/attachments/20180211/5074c519/attachment-0001.html</A>&gt;
</PRE>




<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001017.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
	<LI>Next message: <A HREF="001021.html">[Lightning-dev] AMP: Atomic Multi-Path Payments over Lightning
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1019">[ date ]</a>
              <a href="thread.html#1019">[ thread ]</a>
              <a href="subject.html#1019">[ subject ]</a>
              <a href="author.html#1019">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.linuxfoundation.org/mailman/listinfo/lightning-dev">More information about the Lightning-dev
mailing list</a><br>
</body></html>
